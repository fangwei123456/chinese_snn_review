
@article{che2022differentiable,
  title={Differentiable Hierarchical and Surrogate Gradient Search for Spiking Neural Networks},
  author={Che, Kaiwei and Leng, Luziwei and Zhang, Kaixuan and Zhang, Jianguo and Meng, Qinghu and Cheng, Jie and Guo, Qinghai and Liao, Jianxing},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24975--24990},
  year={2022}
}

@article{eshraghian2021training,
	title        = {Training Spiking Neural Networks Using Lessons From Deep Learning},
	author       = {Eshraghian, Jason K. and Ward, Max and Neftci, Emre O. and Wang, Xinxin and Lenz, Gregor and Dwivedi, Girish and Bennamoun, Mohammed and Jeong, Doo Seok and Lu, Wei D.},
	year         = 2023,
	journal      = {Proceedings of the IEEE},
	volume       = 111,
	number       = 9,
	pages        = {1016--1054},
	doi          = {10.1109/JPROC.2023.3308088},
	keywords     = {Deep learning;Neuromorphics;Neurons;Biological neural networks;Training;Brain modeling;Australia;Electronic learning;Brain modeling;Tutorials;Deep learning;neural code;neuromorphic;online learning;spiking neural networks (SNNs)}
}
@software{norse2021,
	title        = {Norse -  a Deep Learning Library for Spiking Neural Networks},
	author       = {Pehle, Christian and Pedersen, Jens Egholm},
	year         = 2021,
	doi          = {10.5281/zenodo.4422025},
	version      = {0.0.7}
}
@inproceedings{graves2013hybrid,
	title        = {Hybrid Speech Recognition with Deep Bidirectional LSTM},
	author       = {Graves, Alex and Jaitly, Navdeep and Mohamed, Abdel-rahman},
	year         = 2013,
	booktitle    = {IEEE workshop on Automatic Speech Recognition and Understanding},
	pages        = {273--278},
	organization = {IEEE}
}
@inproceedings{graves2013speech,
	title        = {Speech Recognition with Deep Recurrent Neural Networks},
	author       = {Graves, Alex and Mohamed, Abdel-rahman and Hinton, Geoffrey},
	year         = 2013,
	booktitle    = {IEEE International Conference on Acoustics, Speech and Signal Processing},
	pages        = {6645--6649},
	organization = {IEEE}
}
@inproceedings{vaswani2017attention,
	title        = {Attention Is All You Need},
	author       = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
	year         = 2017,
	booktitle    = {Advances in Neural Information Processing Systems},
	volume       = 30
}
@inproceedings{sennrich2015neural,
	title        = {Neural Machine Translation of Rare Words with Subword Units},
	author       = {Sennrich, Rico  and Haddow, Barry  and Birch, Alexandra},
	year         = 2016,
	booktitle    = {Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics},
	address      = {Berlin, Germany},
	pages        = {1715--1725},
	doi          = {10.18653/v1/P16-1162}
}
@inproceedings{bahdanau2014neural,
	title        = {Neural Machine Translation by Jointly Learning to Align and Translate},
	author       = {Dzmitry Bahdanau and Kyunghyun Cho and Yoshua Bengio},
	year         = 2015,
	booktitle    = {International Conference on Learning Representations},
	cdate        = 1420070400000
}
@inproceedings{sutskever2014sequence,
	title        = {Sequence to Sequence Learning with Neural Networks},
	author       = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
	year         = 2014,
	booktitle    = {Advances in Neural Information Processing Systems},
	volume       = 27
}
@article{shd,
	title        = {The Heidelberg Spiking Data Sets for the Systematic Evaluation of Spiking Neural Networks},
	author       = {Cramer, Benjamin and Stradmann, Yannik and Schemmel, Johannes and Zenke, Friedemann},
	year         = 2022,
	journal      = {IEEE Transactions on Neural Networks and Learning Systems},
	volume       = 33,
	number       = 7,
	pages        = {2744--2757},
	doi          = {10.1109/TNNLS.2020.3044364}
}
@inproceedings{fang2021incorporating,
	title        = {Incorporating Learnable Membrane Time Constant to Enhance Learning of Spiking Neural Networks},
	author       = {Fang, Wei and Yu, Zhaofei and Chen, Yanqi and Masquelier, Timoth{\'e}e and Huang, Tiejun and Tian, Yonghong},
	year         = 2021,
	booktitle    = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages        = {2661--2671}
}
@article{hodgkin1952quantitative,
	title        = {A Quantitative Description of Membrane Current and Its Application to Conduction and Excitation in Nerve},
	author       = {Hodgkin, Alan L and Huxley, Andrew F},
	year         = 1952,
	journal      = {The Journal of Physiology},
	volume       = 117,
	number       = 4,
	pages        = {500--544}
}
@article{izhikevich2003simple,
	title        = {Simple Model of Spiking Neurons},
	author       = {Izhikevich, Eugene M},
	year         = 2003,
	journal      = {IEEE Transactions on Neural Networks},
	volume       = 14,
	number       = 6,
	pages        = {1569--1572}
}
@book{gerstner2014neuronal,
	title        = {Neuronal Dynamics: from Single Neurons to Networks and Models of Cognition},
	author       = {Gerstner, Wulfram and Kistler, Werner M and Naud, Richard and Paninski, Liam},
	year         = 2014
}
@article{ledinauskas2020training,
	title        = {Training Deep Spiking Neural Networks},
	author       = {Ledinauskas, Eimantas and Ruseckas, Julius and Jur{\v{s}}{\.e}nas, Alfonsas and Bura{\v{c}}as, Giedrius},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2006.04436}
}
@article{10.3389/fnins.2019.00095,
	title        = {Going Deeper in Spiking Neural Networks: VGG and Residual Architectures},
	author       = {Sengupta, Abhronil and Ye, Yuting and Wang, Robert and Liu, Chiao and Roy, Kaushik},
	year         = 2019,
	journal      = {Frontiers in Neuroscience},
	volume       = 13,
	doi          = {10.3389/fnins.2019.00095},
	issn         = {1662-453X},
	abstract     = {Over the past few years, Spiking Neural Networks (SNNs) have become popular as a possible pathway to enable low-power event-driven neuromorphic hardware. However, their application in machine learning have largely been limited to very shallow neural network architectures for simple problems. In this paper, we propose a novel algorithmic technique for generating an SNN with a deep architecture, and demonstrate its effectiveness on complex visual recognition problems such as CIFAR-10 and ImageNet. Our technique applies to both VGG and Residual network architectures, with significantly better accuracy than the state-of-the-art. Finally, we present analysis of the sparse event-driven computations to demonstrate reduced hardware overhead when operating in the spiking domain.}
}
@article{10.3389/fnins.2021.608567,
	title        = {Is Neuromorphic MNIST Neuromorphic? Analyzing the Discriminative Power of Neuromorphic Datasets in the Time Domain},
	author       = {Iyer, Laxmi R. and Chua, Yansong and Li, Haizhou},
	year         = 2021,
	journal      = {Frontiers in Neuroscience},
	volume       = 15,
	doi          = {10.3389/fnins.2021.608567},
	issn         = {1662-453X}
}
@article{10.3389/fnins.2015.00437,
	title        = {Converting Static Image Datasets to Spiking Neuromorphic Datasets Using Saccades},
	author       = {Orchard, Garrick and Jayawant, Ajinkya and Cohen, Gregory K. and Thakor, Nitish},
	year         = 2015,
	journal      = {Frontiers in Neuroscience},
	volume       = 9,
	doi          = {10.3389/fnins.2015.00437},
	issn         = {1662-453X},
	abstract     = {Creating datasets for Neuromorphic Vision is a challenging task. A lack of available recordings from Neuromorphic Vision sensors means that data must typically be recorded specifically for dataset creation rather than collecting and labeling existing data. The task is further complicated by a desire to simultaneously provide traditional frame-based recordings to allow for direct comparison with traditional Computer Vision algorithms. Here we propose a method for converting existing Computer Vision static image datasets into Neuromorphic Vision datasets using an actuated pan-tilt camera platform. Moving the sensor rather than the scene or image is a more biologically realistic approach to sensing and eliminates timing artifacts introduced by monitor updates when simulating motion on a computer monitor. We present conversion of two popular image datasets (MNIST and Caltech101) which have played important roles in the development of Computer Vision, and we provide performance metrics on these datasets using spike-based recognition algorithms. This work contributes datasets for future use in the field, as well as results from spike-based algorithms against which future works can compare. Furthermore, by converting datasets already popular in Computer Vision, we enable more direct comparison with frame-based approaches.}
}
@inproceedings{he2015delving,
	title        = {Delving Deep into Rectifiers: Surpassing Human-Level Performance on Imagenet Classification},
	author       = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	year         = 2015,
	booktitle    = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages        = {1026--1034}
}
@inproceedings{tan2021efficientnetv2,
	title        = {EfficientNetV2: Smaller Models and Faster Training},
	author       = {Tan, Mingxing and Le, Quoc},
	year         = 2021,
	booktitle    = {International Conference on Machine Learning},
	pages        = {10096--10106},
	organization = {PMLR}
}
@inproceedings{tan2019efficientnet,
	title        = {EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks},
	author       = {Tan, Mingxing and Le, Quoc},
	year         = 2019,
	booktitle    = {International Conference on Machine Learning},
	pages        = {6105--6114},
	organization = {PMLR}
}
@inproceedings{dosovitskiy2020image,
	title        = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
	author       = {Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
	year         = 2021,
	booktitle    = {International Conference on Learning Representations}
}
@inproceedings{liu2021swin,
	title        = {Swin Transformer: Hierarchical Vision Transformer Using Shifted Windows},
	author       = {Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
	year         = 2021,
	booktitle    = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages        = {10012--10022}
}
@inproceedings{liu2022convnet,
	title        = {A ConvNet for the 2020s},
	author       = {Liu, Zhuang and Mao, Hanzi and Wu, Chao-Yuan and Feichtenhofer, Christoph and Darrell, Trevor and Xie, Saining},
	year         = 2022,
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {11976--11986}
}
@inproceedings{guo2022recdis,
	title        = {RecDis-SNN: Rectifying Membrane Potential Distribution for Directly Training Spiking Neural Networks},
	author       = {Guo, Yufei and Tong, Xinyi and Chen, Yuanpei and Zhang, Liwen and Liu, Xiaode and Ma, Zhe and Huang, Xuhui},
	year         = 2022,
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {326--335}
}
@inproceedings{sironi2018hats,
	title        = {Hats: Histograms of Averaged Time Surfaces for Robust Event-Based Object Classification},
	author       = {Sironi, Amos and Brambilla, Manuele and Bourdis, Nicolas and Lagorce, Xavier and Benosman, Ryad},
	year         = 2018,
	booktitle    = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages        = {1731--1740}
}
@article{xing2020new,
	title        = {A New Spiking Convolutional Recurrent Neural Network (SCRNN) With Applications to Event-Based Hand Gesture Recognition},
	author       = {Xing, Yannan and Di Caterina, Gaetano and Soraghan, John},
	year         = 2020,
	journal      = {Frontiers in Neuroscience},
	volume       = 14,
	pages        = 1143,
	doi          = {10.3389/fnins.2020.590164},
	issn         = {1662-453X}
}
@inproceedings{LISNN,
	title        = {LISNN: Improving Spiking Neural Networks with Lateral Interactions for Robust Object Recognition},
	author       = {Cheng, Xiang and Hao, Yunzhe and Xu, Jiaming and Xu, Bo},
	year         = 2020,
	booktitle    = {International Joint Conference on Artificial Intelligence},
	pages        = {1519--1525},
	doi          = {10.24963/ijcai.2020/211}
}
@inproceedings{Bi_2019_ICCV,
	title        = {Graph-Based Object Classification for Neuromorphic Vision Sensing},
	author       = {Bi, Yin and Chadha, Aaron and Abbas, Alhabib and Bourtsoulatze, Eirina and Andreopoulos, Yiannis},
	year         = 2019,
	booktitle    = {Proceedings of the IEEE/CVF International Conference on Computer Vision}
}
@article{10.3389/fnins.2017.00309,
	title        = {CIFAR10-DVS: an Event-Stream Dataset for Object Classification},
	author       = {Li, Hongmin and Liu, Hanchao and Ji, Xiangyang and Li, Guoqi and Shi, Luping},
	year         = 2017,
	journal      = {Frontiers in Neuroscience},
	volume       = 11,
	doi          = {10.3389/fnins.2017.00309},
	issn         = {1662-453X}
}
@article{FMNIST,
	title        = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms},
	author       = {Xiao, Han and Rasul, Kashif and Vollgraf, Roland},
	year         = 2017,
	journal      = {arXiv preprint arXiv:1708.07747}
}
@article{10.3389/fnins.2021.726582,
	title        = {ES-ImageNet: a Million Event-Stream Classification Dataset for Spiking Neural Networks},
	author       = {Lin, Yihan and Ding, Wei and Qiang, Shaohua and Deng, Lei and Li, Guoqi},
	year         = 2021,
	journal      = {Frontiers in Neuroscience},
	volume       = 15,
	doi          = {10.3389/fnins.2021.726582},
	issn         = {1662-453X},
	abstract     = {With event-driven algorithms, especially spiking neural networks (SNNs), achieving continuous improvement in neuromorphic vision processing, a more challenging event-stream dataset is urgently needed. However, it is well-known that creating an ES-dataset is a time-consuming and costly task with neuromorphic cameras like dynamic vision sensors (DVS). In this work, we propose a fast and effective algorithm termed Omnidirectional Discrete Gradient (ODG) to convert the popular computer vision dataset ILSVRC2012 into its event-stream (ES) version, generating about 1,300,000 frame-based images into ES-samples in 1,000 categories. In this way, we propose an ES-dataset called ES-ImageNet, which is dozens of times larger than other neuromorphic classification datasets at present and completely generated by the software. The ODG algorithm implements image motion to generate local value changes with discrete gradient information in different directions, providing a low-cost and high-speed method for converting frame-based images into event streams, along with Edge-Integral to reconstruct the high-quality images from event streams. Furthermore, we analyze the statistics of ES-ImageNet in multiple ways, and a performance benchmark of the dataset is also provided using both famous deep neural network algorithms and spiking neural network algorithms. We believe that this work shall provide a new large-scale benchmark dataset for SNNs and neuromorphic vision.}
}
@inproceedings{neunorm,
	title        = {Direct Training for Spiking Neural Networks: Faster, Larger, Better},
	author       = {Wu, Yujie and Deng, Lei and Li, Guoqi and Zhu, Jun and Xie, Yuan and Shi, Luping},
	year         = 2019,
	booktitle    = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume       = 33,
	number       = {01},
	pages        = {1311--1318},
	doi          = {10.1609/aaai.v33i01.33011311}
}
@inproceedings{SNN-IIR,
	title        = {Exploiting Neuron and Synapse Filter Dynamics in Spatial Temporal Learning of Deep Spiking Neural Network},
	author       = {Fang, Haowen and Shrestha, Amar and Zhao, Ziyi and Qiu, Qinru},
	year         = 2020,
	booktitle    = {International Joint Conference on Artificial Intelligence},
	pages        = {2799--2806},
	doi          = {10.24963/ijcai.2020/388},
}
@inproceedings{SEWResNet,
	title        = {Deep Residual Learning in Spiking Neural Networks},
	author       = {Fang, Wei and Yu, Zhaofei and Chen, Yanqi and Huang, Tiejun and Masquelier, Timoth{\'e}e and Tian, Yonghong},
	year         = 2021,
	booktitle    = {Advances in Neural Information Processing Systems},
	volume       = 34
}

@inproceedings{NEURIPS2023_ca0f5358,
	author = {Yao, Man and Hu, JiaKui and Zhou, Zhaokun and Yuan, Li and Tian, Yonghong and Xu, Bo and Li, Guoqi},
	booktitle = {Advances in Neural Information Processing Systems},
	pages = {64043--64058},
	title = {Spike-Driven Transformer},
	volume = {36},
	year = {2023}
}



@article{deep-learning-nature,
	title        = {Deep Learning},
	author       = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	year         = 2015,
	journal      = {Nature},
	volume       = 521,
	number       = 7553,
	pages        = {436--444}
}
@article{lee2016training,
	title        = {Training Deep Spiking Neural Networks Using Backpropagation},
	author       = {Lee, Jun Haeng and Delbruck, Tobi and Pfeiffer, Michael},
	year         = 2016,
	journal      = {Frontiers in Neuroscience},
	volume       = 10,
	pages        = 508
}
@article{lee2020enabling,
	title        = {Enabling Spike-based Backpropagation for Training Deep Neural Network Architectures},
	author       = {Lee, Chankyu and Sarwar, Syed Shakib and Panda, Priyadarshini and Srinivasan, Gopalakrishnan and Roy, Kaushik},
	year         = 2020,
	journal      = {Frontiers in Neuroscience},
	volume       = 14
}
@book{cheng2014professional,
	title        = {Professional CUDA C Programming},
	author       = {Cheng, John and Grossman, Max and McKercher, Ty},
	year         = 2014
}
@article{Zenke2020.06.29.176925,
	title        = {The Remarkable Robustness of Surrogate Gradient Learning for Instilling Complex Function in Spiking Neural Networks},
	author       = {Zenke, Friedemann and Vogels, Tim P},
	year         = 2020,
	journal      = {BioRxiv}
}
@inproceedings{he2016deep,
	title        = {Deep Residual Learning for Image Recognition},
	author       = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	year         = 2016,
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {770--778}
}
@article{krizhevsky2014one,
	title        = {One Weird Trick for Parallelizing Convolutional Neural Networks},
	author       = {Krizhevsky, Alex},
	year         = 2014,
	journal      = {arXiv preprint arXiv:1404.5997}
}
@inproceedings{han2020rmp,
	title        = {RMP-SNN: Residual Membrane Potential Neuron for Enabling Deeper High-Accuracy and Low-Latency Spiking Neural Network},
	author       = {Han, Bing and Srinivasan, Gopalakrishnan and Roy, Kaushik},
	year         = 2020,
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {13558--13567}
}
@inproceedings{pmlr-v139-li21d,
	title        = {A Free Lunch From ANN: Towards Efficient, Accurate Spiking Neural Networks Calibration},
	author       = {Li, Yuhang and Deng, Shikuang and Dong, Xin and Gong, Ruihao and Gu, Shi},
	year         = 2021,
	booktitle    = {International Conference on Machine Learning},
	volume       = 139,
	pages        = {6316--6325},
	pdf          = {http://proceedings.mlr.press/v139/li21d/li21d.pdf}
}
@article{neftci2019surrogate,
	title        = {Surrogate Gradient Learning in Spiking Neural Networks: Bringing the Power of Gradient-Based Optimization to Spiking Neural Networks},
	author       = {Neftci, Emre O and Mostafa, Hesham and Zenke, Friedemann},
	year         = 2019,
	journal      = {IEEE Signal Processing Magazine},
	volume       = 36,
	number       = 6,
	pages        = {51--63}
}
@inproceedings{nishino2017cupy,
	title        = {CuPy: a NumPy-Compatible Library for NVIDIA GPU Calculations},
	author       = {Okuta, Ryosuke and Unno, Yuya and Nishino, Daisuke and Hido, Shohei and Loomis, Crissman},
	year         = 2017,
	booktitle    = {Advances in Neural Information Processing Systems}
}
@article{merolla2014million,
	title        = {A Million Spiking-Neuron Integrated Circuit with a Scalable Communication Network and Interface},
	author       = {Paul A. Merolla  and John V. Arthur  and Rodrigo Alvarez-Icaza  and Andrew S. Cassidy  and Jun Sawada  and Filipp Akopyan  and Bryan L. Jackson  and Nabil Imam  and Chen Guo  and Yutaka Nakamura  and Bernard Brezzo  and Ivan Vo  and Steven K. Esser  and Rathinakumar Appuswamy  and Brian Taba  and Arnon Amir  and Myron D. Flickner  and William P. Risk  and Rajit Manohar  and Dharmendra S. Modha},
	year         = 2014,
	journal      = {Science},
	volume       = 345,
	number       = 6197,
	pages        = {668--673}
}
@article{loihi,
	title        = {Loihi: a Neuromorphic Manycore Processor with On-Chip Learning},
	author       = {Davies, Mike and Srinivasa, Narayan and Lin, Tsung-Han and Chinya, Gautham and Cao, Yongqiang and Choday, Sri Harsha and Dimou, Georgios and Joshi, Prasad and Imam, Nabil and Jain, Shweta and Liao, Yuyun and Lin, Chit-Kwan and Lines, Andrew and Liu, Ruokun and Mathaikutty, Deepak and McCoy, Steven and Paul, Arnab and Tse, Jonathan and Venkataramanan, Guruguhanathan and Weng, Yi-Hsin and Wild, Andreas and Yang, Yoonseok and Wang, Hong},
	year         = 2018,
	journal      = {IEEE Micro},
	volume       = 38,
	number       = 1,
	pages        = {82--99},
	doi          = {10.1109/MM.2018.112130359}
}
@article{pei2019towards,
	title        = {Towards Artificial General Intelligence with Hybrid Tianjic Chip Architecture},
	author       = {Pei, Jing and Deng, Lei and Song, Sen and Zhao, Mingguo and Zhang, Youhui and Wu, Shuang and Wang, Guanrui and Zou, Zhe and Wu, Zhenzhi and He, Wei and Chen, Feng and Deng, Ning and Wu, Si and Wang, Yu and Wu, Yujie and Yang, Zheyu and Ma, Cheng and Li, Guoqi and Han, Wentao and Li, Huanglong and Wu, Huaqiang and Zhao, Rong and Xie, Yuan and Shi, Luping},
	year         = 2019,
	journal      = {Nature},
	volume       = 572,
	number       = 7767,
	pages        = {106--111}
}
@article{spaun,
	title        = {A Large-Scale Model of the Functioning Brain},
	author       = {Chris Eliasmith  and Terrence C. Stewart  and Xuan Choo  and Trevor Bekolay  and Travis DeWolf  and Yichuan Tang  and Daniel Rasmussen},
	year         = 2012,
	journal      = {Science},
	volume       = 338,
	number       = 6111,
	pages        = {1202--1205},
	doi          = {10.1126/science.1225266}
}
@book{hebb1949the,
	title        = {The Organization of Behavior: a Neuropsychological Theory},
	author       = {Hebb, Donald Olding},
	year         = 2005
}
@article{bi1998synaptic,
	title        = {Synaptic Modifications in Cultured Hippocampal Neurons: Dependence on Spike Timing, Synaptic Strength, and Postsynaptic Cell Type},
	author       = {Bi, Guo-qiang and Poo, Mu-ming},
	year         = 1998,
	journal      = {Journal of Neuroscience},
	volume       = 18,
	number       = 24,
	pages        = {10464--10472}
}
@article{MNIST,
	title        = {Gradient-Based Learning Applied to Document Recognition},
	author       = {LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
	year         = 1998,
	journal      = {Proceedings of the IEEE},
	volume       = 86,
	number       = 11,
	pages        = {2278--2324}
}
@article{BOHTE200217,
	title        = {Error-Backpropagation in Temporally Encoded Networks of Spiking Neurons},
	author       = {Bohte, Sander M and Kok, Joost N and La Poutre, Han},
	year         = 2002,
	journal      = {Neurocomputing},
	volume       = 48,
	number       = {1-4},
	pages        = {17--37}
}
@article{tempotron,
	title        = {The Tempotron: a Neuron that Learns Spike Timing-Based Decisions},
	author       = {G{\"u}tig, Robert and Sompolinsky, Haim},
	year         = 2006,
	journal      = {Nature Neuroscience},
	volume       = 9,
	number       = 3,
	pages        = {420--428}
}
@article{ponulak2010supervised,
	title        = {Supervised Learning in Spiking Neural Networks with ReSuMe: Sequence Learning, Classification, and Spike Shifting},
	author       = {Ponulak, Filip and Kasi{\'n}ski, Andrzej},
	year         = 2010,
	journal      = {Neural Computation},
	volume       = 22,
	number       = 2,
	pages        = {467--510}
}
@article{mohemmed2012span,
	title        = {SPAN: Spike Pattern Association Neuron for Learning Spatio-Temporal Spike Patterns},
	author       = {Mohemmed, Ammar and Schliebs, Stefan and Matsuda, Satoshi and Kasabov, Nikola},
	year         = 2012,
	journal      = {International Journal of Neural Systems},
	volume       = 22,
	number       = {04},
	pages        = 1250012
}
@article{li2023spikeclip,
	title        = {SpikeCLIP: a Contrastive Language-Image Pretrained Spiking Neural Network},
	author       = {Li, Tianlong and Liu, Wenhao and Lv, Changze and Xu, Jianhan and Zhang, Cenyuan and Wu, Muling and Zheng, Xiaoqing and Huang, Xuanjing},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2310.06488}
}
@article{lv2023spikebert,
	title        = {SpikeBERT: a Language Spikformer Trained with Two-Stage Knowledge Distillation from BERT},
	author       = {Lv, Changze and Li, Tianlong and Xu, Jianhan and Gu, Chenxi and Ling, Zixuan and Zhang, Cenyuan and Zheng, Xiaoqing and Huang, Xuanjing},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2308.15122}
}
@inproceedings{szegedy2015going,
	title        = {Going Deeper with Convolutions},
	author       = {Szegedy, Christian and Wei Liu and Yangqing Jia and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
	year         = 2015,
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {1--9},
	doi          = {10.1109/CVPR.2015.7298594}
}
@inproceedings{girshick2014rich,
	title        = {Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation},
	author       = {Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
	year         = 2014,
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {580--587}
}
@inproceedings{liu2016ssd,
	title        = {SSD: Single Shot Multibox Detector},
	author       = {Liu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng-Yang and Berg, Alexander C},
	year         = 2016,
	booktitle    = {European Conference on Computer Vision},
	pages        = {21--37},
	organization = {Springer}
}
@inproceedings{redmon2016you,
	title        = {You Only Look Once: Unified, Real-Time Object Detection},
	author       = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
	year         = 2016,
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {779--788}
}
@article{mnih2015human,
	title        = {Human-Level Control through Deep Reinforcement Learning},
	author       = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
	year         = 2015,
	day          = {01},
	journal      = {Nature},
	volume       = 518,
	number       = 7540,
	pages        = {529--533},
	doi          = {10.1038/nature14236},
	issn         = {1476-4687}
}
@article{silver2016mastering,
	title        = {Mastering the Game of Go with Deep Neural Networks and Tree Search},
	author       = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
	year         = 2016,
	journal      = {Nature},
	volume       = 529,
	number       = 7587,
	pages        = {484--489}
}
@inproceedings{shrestha2018slayer,
	title        = {SLAYER: Spike Layer Error Reassignment in Time},
	author       = {Shrestha, Sumit Bam and Orchard, Garrick},
	year         = 2018,
	booktitle    = {Advances in Neural Information Processing Systems},
	pages        = {1419--1428}
}
@article{hunsberger2015spiking,
	title        = {Spiking Deep Networks with LIF Neurons},
	author       = {Hunsberger, Eric and Eliasmith, Chris},
	year         = 2015,
	journal      = {arXiv preprint arXiv:1510.08829}
}
@article{Bodo2017Conversion,
	title        = {Conversion of Continuous-Valued Deep Networks to Efficient Event-Driven Networks for Image Classification},
	author       = {Rueckauer, Bodo and Lungu, Iulia-Alexandra and Hu, Yuhuang and Pfeiffer, Michael and Liu, Shih-Chii},
	year         = 2017,
	journal      = {Frontiers in Neuroscience},
	volume       = 11,
	pages        = 682
}
@article{cao2015spiking,
	title        = {Spiking Deep Convolutional Neural Networks for Energy-Efficient Object Recognition},
	author       = {Cao, Yongqiang and Chen, Yang and Khosla, Deepak},
	year         = 2015,
	journal      = {International Journal of Computer Vision},
	volume       = 113,
	number       = 1,
	pages        = {54--66}
}
@article{CIFAR10,
	title        = {Learning Multiple Layers of Features from Tiny Images},
	author       = {Krizhevsky, Alex and Hinton, Geoffrey},
	year         = 2009
}
@article{russakovsky2015imagenet,
	title        = {ImageNet Large Scale Visual Recognition Challenge},
	author       = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and Berg, Alexander C. and Fei-Fei, Li},
	year         = 2015,
	journal      = {International Journal of Computer Vision},
	volume       = 115,
	number       = 3,
	pages        = {211--252}
}
@inproceedings{zheng2020going,
	title        = {Going Deeper With Directly-Trained Larger Spiking Neural Networks},
	author       = {Zheng, Hanle and Wu, Yujie and Deng, Lei and Hu, Yifan and Li, Guoqi},
	year         = 2021,
	booktitle    = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume       = 35,
	number       = 12,
	pages        = {11062--11070}
}
@inproceedings{huang2023deep,
	title        = {Deep Spiking Neural Networks with High Representation Similarity Model Visual Pathways of Macaque and Mouse},
	author       = {Huang, Liwei and Ma, Zhengyu and Yu, Liutao and Zhou, Huihui and Tian, Yonghong},
	year         = 2023,
	booktitle    = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume       = 37,
	number       = 1,
	pages        = {31--39}
}
@inproceedings{han2020deep,
	title        = {Deep Spiking Neural Network: Energy Efficiency Through Time based Coding},
	author       = {Han, Bing and Roy, Kaushik},
	year         = 2020,
	booktitle    = {European Conference on Computer Vision},
	pages        = {388--404}
}
@inproceedings{deng2021optimal,
	title        = {Optimal Conversion of Conventional Artificial Neural Networks to Spiking Neural Networks},
	author       = {Shikuang Deng and Shi Gu},
	year         = 2021,
	booktitle    = {International Conference on Learning Representations}
}
@book{carnevale2006neuron,
	title        = {The NEURON Book},
	author       = {Carnevale, Nicholas T and Hines, Michael L},
	year         = 2006
}
@article{gewaltig2007nest,
        title        = {Nest (Neural Simulation Tool)},
	author       = {Gewaltig, Marc-Oliver and Diesmann, Markus},
	year         = 2007,
	journal      = {Scholarpedia},
	volume       = 2,
	number       = 4,
	pages        = 1430
}
@article{Stimberg2019,
	title        = {Brian 2, an Intuitive and Efficient Neural Simulator},
	author       = {Stimberg, Marcel and Brette, Romain and Goodman, Dan FM},
	year         = 2019,
	journal      = {eLife},
	volume       = 8,
	pages        = {e47314},
	doi          = {10.7554/eLife.47314},
	issn         = {2050-084X}
}
@article{cornelis2012python,
	title        = {Python as a Federation Tool for Genesis 3.0},
	author       = {Cornelis, Hugo and Rodriguez, Armando L and Coop, Allan D and Bower, James M},
	year         = 2012,
	journal      = {PLOS One},
	volume       = 7,
	number       = 1,
	pages        = {e29018}
}
@article{10.3389/neuro.11.005.2008,
	title        = {Brian: a Simulator for Spiking Neural Networks in Python},
	author       = {Goodman, Dan and Brette, Romain},
	year         = 2008,
	journal      = {Frontiers in Neuroinformatics},
	volume       = 2,
	doi          = {10.3389/neuro.11.005.2008},
	issn         = {1662-5196}
}
@article{bekolay2014nengo,
	title        = {Nengo: a Python Tool for Building Large-scale Functional Brain Models},
	author       = {Bekolay, Trevor and Bergstra, James and Hunsberger, Eric and DeWolf, Travis and Stewart, Terrence C and Rasmussen, Daniel and Choo, Xuan and Voelker, Aaron and Eliasmith, Chris},
	year         = 2014,
	journal      = {Frontiers in Neuroinformatics},
	volume       = 7,
	pages        = 48
}
@article{10.3389/fninf.2018.00089,
	title        = {BindsNET: a Machine Learning-Oriented Spiking Neural Networks Library in Python},
	author       = {Hazan, Hananel and Saunders, Daniel J. and Khan, Hassaan and Patel, Devdhar and Sanghavi, Darpan T. and Siegelmann, Hava T. and Kozma, Robert},
	year         = 2018,
	journal      = {Frontiers in Neuroinformatics},
	volume       = 12,
	doi          = {10.3389/fninf.2018.00089},
	issn         = {1662-5196},
	abstract     = {The development of spiking neural network simulation software is a critical component enabling the modeling of neural systems and the development of biologically inspired algorithms. Existing software frameworks support a wide range of neural functionality, software abstraction levels, and hardware devices, yet are typically not suitable for rapid prototyping or application to problems in the domain of machine learning. In this paper, we describe a new Python package for the simulation of spiking neural networks, specifically geared toward machine learning and reinforcement learning. Our software, called <monospace>BindsNET</monospace><xref ref-type="fn" rid="fn0001"><sup>1</sup></xref>, enables rapid building and simulation of spiking networks and features user-friendly, concise syntax. <monospace>BindsNET</monospace> is built on the <monospace>PyTorch</monospace> deep neural networks library, facilitating the implementation of spiking neural networks on fast CPU and GPU computational platforms. Moreover, the <monospace>BindsNET</monospace> framework can be adjusted to utilize other existing computing and hardware backends; e.g., <monospace>TensorFlow</monospace> and <monospace>SpiNNaker</monospace>. We provide an interface with the OpenAI <monospace>gym</monospace> library, allowing for training and evaluation of spiking networks on reinforcement learning environments. We argue that this package facilitates the use of spiking networks for large-scale machine learning problems and show some simple examples by using <monospace>BindsNET</monospace> in practice.}
}
@article{10.3389/fnins.2019.00625,
	title        = {SpykeTorch: Efficient Simulation of Convolutional Spiking Neural Networks With at Most One Spike per Neuron},
	author       = {Mozafari, Milad and Ganjtabesh, Mohammad and Nowzari-Dalini, Abbas and Masquelier, Timothée},
	year         = 2019,
	journal      = {Frontiers in Neuroscience},
	volume       = 13,
	doi          = {10.3389/fnins.2019.00625},
	issn         = {1662-453X},
	abstract     = {Application of deep convolutional spiking neural networks (SNNs) to artificial intelligence (AI) tasks has recently gained a lot of interest since SNNs are hardware-friendly and energy-efficient. Unlike the non-spiking counterparts, most of the existing SNN simulation frameworks are not practically efficient enough for large-scale AI tasks. In this paper, we introduce SpykeTorch, an open-source high-speed simulation framework based on PyTorch. This framework simulates convolutional SNNs with at most one spike per neuron and the rank-order encoding scheme. In terms of learning rules, both spike-timing-dependent plasticity (STDP) and reward-modulated STDP (R-STDP) are implemented, but other rules could be implemented easily. Apart from the aforementioned properties, SpykeTorch is highly generic and capable of reproducing the results of various studies. Computations in the proposed framework are tensor-based and totally done by PyTorch functions, which in turn brings the ability of just-in-time optimization for running on CPUs, GPUs, or Multi-GPU platforms.}
}
@article{lichtsteiner2008128,
	title        = {A 128$\times$128 120 dB 15$\mu$s Latency Asynchronous Temporal Contrast Vision Sensor},
	author       = {Lichtsteiner, Patrick and Posch, Christoph and Delbruck, Tobi},
	year         = 2008,
	journal      = {IEEE Journal of Solid-State Circuits},
	volume       = 43,
	number       = 2,
	pages        = {566--576}
}
@article{posch2010qvga,
	title        = {A QVGA 143 dB Dynamic Range Frame-free PWM Image Sensor with Lossless Pixel-Level Video Compression and Time-domain CDS},
	author       = {Posch, Christoph and Matolin, Daniel and Wohlgenannt, Rainer},
	year         = 2010,
	journal      = {IEEE Journal of Solid-State Circuits},
	volume       = 46,
	number       = 1,
	pages        = {259--275}
}
@article{felleman1991distributed,
	title        = {Distributed Hierarchical Processing in the Primate Cerebral Cortex},
	author       = {Felleman, Daniel J and Van Essen, David C},
	year         = 1991,
	journal      = {Cerebral Cortex},
	volume       = 1,
	number       = 1,
	pages        = {1--47}
}
@article{sporns2004small,
	title        = {The Small World of the Cerebral Cortex},
	author       = {Sporns, Olaf and Zwi, Jonathan D},
	year         = 2004,
	journal      = {Neuroinformatics},
	volume       = 2,
	pages        = {145--162}
}
@article{brandli2014240,
	title        = {A 240$\times$ 180 130 db 3 $\mu$s Latency Global Shutter Spatiotemporal Vision Sensor},
	author       = {Brandli, Christian and Berner, Raphael and Yang, Minhao and Liu, Shih-Chii and Delbruck, Tobi},
	year         = 2014,
	journal      = {IEEE Journal of Solid-State Circuits},
	volume       = 49,
	number       = 10,
	pages        = {2333--2341}
}
@article{mcanally1996auditory,
	title        = {Auditory Temporal Coding in Dyslexia},
	author       = {Mcanally, Ken I and Stein, John F},
	year         = 1996,
	journal      = {Proceedings: Biological Sciences},
	volume       = 263,
	number       = 1373,
	pages        = {961--965}
}
@article{cortes1995support,
	title        = {Support-Vector Networks},
	author       = {Cortes, Corinna and Vapnik, Vladimir},
	year         = 1995,
	journal      = {Machine Learning},
	volume       = 20,
	number       = 3,
	pages        = {273--297}
}
@article{silver2017mastering,
	title        = {Mastering the Game of Go without Human Knowledge},
	author       = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
	year         = 2017,
	journal      = {Nature},
	volume       = 550,
	number       = 7676,
	pages        = {354--359}
}
@article{hornik1989multilayer,
	title        = {Multilayer Feedforward Networks Are Universal Approximators},
	author       = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
	year         = 1989,
	journal      = {Neural Networks},
	volume       = 2,
	number       = 5,
	pages        = {359--366}
}
@article{maass1997networks,
	title        = {Networks of Spiking Neurons: the Third Generation of Neural Network Models},
	author       = {Maass, Wolfgang},
	year         = 1997,
	journal      = {Neural Networks},
	volume       = 10,
	number       = 9,
	pages        = {1659--1671}
}
@article{izhikevich2008large,
	title        = {Large-scale Model of Mammalian Thalamocortical Systems},
	author       = {Izhikevich, Eugene M and Edelman, Gerald M},
	year         = 2008,
	journal      = {Proceedings of the National Academy of Sciences},
	volume       = 105,
	number       = 9,
	pages        = {3593--3598}
}
@inproceedings{NEURIPS2020_e2e5096d,
	title        = {Unifying Activation- and Timing-based Learning Rules for Spiking Neural Networks},
	author       = {Kim, Jinseok and Kim, Kyungsu and Kim, Jae-Joon},
	year         = 2020,
	booktitle    = {Advances in Neural Information Processing Systems},
	volume       = 33,
	pages        = {19534--19544}
}
@article{diehl2015unsupervised,
	title        = {Unsupervised Learning of Digit Recognition Using Spike-timing-Dependent Plasticity},
	author       = {Diehl, Peter U and Cook, Matthew},
	year         = 2015,
	journal      = {Frontiers in Computational Neuroscience},
	volume       = 9,
	pages        = 99
}
@inproceedings{HM-2BP,
	title        = {Hybrid Macro/Micro Level Backpropagation for Training Deep Spiking Neural Networks},
	author       = {Jin, Yingyezhe and Zhang, Wenrui and Li, Peng},
	year         = 2018,
	booktitle    = {Advances in Neural Information Processing Systems},
	pages        = {7005--7015}
}
@article{10.3389/neuro.11.011.2008,
	title        = {PyNN: a Common Interface for Neuronal Network Simulators},
	author       = {Davison, Andrew and Brüderle, Daniel and Eppler, Jochen and Kremkow, Jens and Muller, Eilif and Pecevski, Dejan and Perrinet, Laurent and Yger, Pierre},
	year         = 2009,
	journal      = {Frontiers in Neuroinformatics},
	volume       = 2,
	doi          = {10.3389/neuro.11.011.2008},
	issn         = {1662-5196},
	abstract     = {Computational neuroscience has produced a diversity of software for simulations of networks of spiking neurons, with both negative and positive consequences. On the one hand, each simulator uses its own programming or configuration language, leading to considerable difficulty in porting models from one simulator to another. This impedes communication between investigators and makes it harder to reproduce and build on the work of others. On the other hand, simulation results can be cross-checked between different simulators, giving greater confidence in their correctness, and each simulator has different optimizations, so the most appropriate simulator can be chosen for a given modelling task. A common programming interface to multiple simulators would reduce or eliminate the problems of simulator diversity while retaining the benefits. PyNN is such an interface, making it possible to write a simulation script once, using the Python programming language, and run it without modification on any supported simulator (currently NEURON, NEST, PCSIM, Brian and the Heidelberg VLSI neuromorphic hardware). PyNN increases the productivity of neuronal network modelling by providing high-level abstraction, by promoting code sharing and reuse, and by providing a foundation for simulator-agnostic analysis, visualization and data-management tools. PyNN increases the reliability of modelling studies by making it much easier to check results on multiple simulators. PyNN is open-source software and is available from http://neuralensemble.org/PyNN.}
}
@article{stimberg2020brian2genn,
	title        = {Brian2GeNN: Accelerating Spiking Neural Network Simulations with Graphics Hardware},
	author       = {Stimberg, Marcel and Goodman, Dan FM and Nowotny, Thomas},
	year         = 2020,
	journal      = {Scientific Reports},
	volume       = 10,
	number       = 1,
	pages        = {1--12}
}
@inproceedings{jia2014caffe,
	title        = {Caffe: Convolutional Architecture for Fast Feature Embedding},
	author       = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},
	year         = 2014,
	booktitle    = {Proceedings of the 22nd ACM International Conference on Multimedia},
	address      = {New York, NY, USA},
	series       = {MM '14},
	pages        = {675--678},
	doi          = {10.1145/2647868.2654889},
	isbn         = 9781450330633,
	numpages     = 4,
	keywords     = {computer vision, machine learning, neural networks, open source, parallel computation}
}
@article{li2024efficient,
	title        = {Efficient Training Spiking Neural Networks with Parallel Spiking Unit},
	author       = {Li, Yang and Sun, Yinqian and He, Xiang and Dong, Yiting and Zhao, Dongcheng and Zeng, Yi},
	year         = 2024,
	journal      = {arXiv preprint arXiv:2402.00449}
}
@article{chen2024a,
	title        = {A Parallel Multi-compartment Spiking Neuron For Multi-scale Sequential Modeling},
	author       = {Xinyi Chen and Jibin Wu and Chenxiang Ma and Yinsong Yan and KC Tan},
	year         = 2024
}
@inproceedings{10191884,
	title        = {Accelerating SNN Training with Stochastic Parallelizable Spiking Neurons},
	author       = {Yarga, Sidi Yaya Arnaud and Wood, Sean U. N.},
	year         = 2023,
	booktitle    = {International Joint Conference on Neural Networks},
	pages        = {1--8},
	doi          = {10.1109/IJCNN54540.2023.10191884},
	keywords     = {Training;Linear systems;Recurrent neural networks;Neuromorphics;Neurons;Graphics processing units;Membrane potentials;spiking neural networks;neuromorphic computing;stochastic neurons;parallelization;hardware acceleration}
}
@article{tensorflow2015-whitepaper,
	title        = {Tensorflow: Large-scale Machine Learning on Heterogeneous Distributed Systems},
	author       = {Abadi, Mart{\'\i}n and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and Corrado, Greg S and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and others},
	year         = 2016,
	journal      = {arXiv preprint arXiv:1603.04467}
}
@article{rasmussen2019nengodl,
	title        = {NengoDL: Combining Deep Learning and Neuromorphic Modelling Methods},
	author       = {Rasmussen, Daniel},
	year         = 2019,
	journal      = {Neuroinformatics},
	volume       = 17,
	number       = 4,
	pages        = {611--628}
}
@article{yavuz2016genn,
	title        = {GeNN: a Code Generation Framework for Accelerated Brain Simulations},
	author       = {Yavuz, Esin and Turner, James and Nowotny, Thomas},
	year         = 2016,
	journal      = {Scientific Reports},
	volume       = 6,
	number       = 1,
	pages        = {1--14}
}
@inproceedings{ST-RSBP,
	title        = {Spike-train Level Backpropagation for Training Deep Recurrent Spiking Neural Networks},
	author       = {Zhang, Wenrui and Li, Peng},
	year         = 2019,
	booktitle    = {Advances in Neural Information Processing Systems},
	pages        = {7802--7813}
}
@article{kaiser2020synaptic,
  title={Synaptic Plasticity Dynamics for Deep Continuous Local Learning (DECOLLE)},
  author={Kaiser, Jacques and Mostafa, Hesham and Neftci, Emre},
  journal={Frontiers in Neuroscience},
  volume={14},
  pages={424},
  year={2020},
  publisher={Frontiers Media SA}
}
@article{boser1992training,
	title        = {A Training Algorithm for Optimal Margin Classifiers},
	author       = {Boser, Bernhard E. and Guyon, Isabelle M. and Vapnik, Vladimir N.},
	year         = 1992,
	booktitle    = {Proceedings of the Fifth Annual Workshop on Computational Learning Theory},
	address      = {New York, NY, USA},
	series       = {COLT '92},
	pages        = {144--152},
	doi          = {10.1145/130385.130401},
	isbn         = {089791497X},
	abstract     = {A training algorithm that maximizes the margin between the training patterns and the decision boundary is presented. The technique is applicable to a wide variety of the classification functions, including Perceptrons, polynomials, and Radial Basis Functions. The effective number of parameters is adjusted automatically to match the complexity of the problem. The solution is expressed as a linear combination of supporting patterns. These are the subset of training patterns that are closest to the decision boundary. Bounds on the generalization performance based on the leave-one-out method and the VC-dimension are given. Experimental results on optical character recognition problems demonstrate the good generalization obtained when compared with other learning algorithms.},
	numpages     = 9
}
@article{vanrullen2005spike,
	title        = {Spike Times Make Sense},
	author       = {VanRullen, Rufin and Guyonneau, Rudy and Thorpe, Simon J},
	year         = 2005,
	journal      = {Trends in Neurosciences},
	volume       = 28,
	number       = 1,
	pages        = {1--4}
}
@book{minsky1969perceptrons,
	title        = {Perceptrons},
	author       = {Minsky, Marvin and Papert, Seymour},
	year         = 1969
}
@article{harris2020array,
	title        = {Array Programming with NumPy},
	author       = {Harris, Charles R. and Millman, K. Jarrod and van der Walt, St{\'e}fan J. and Gommers, Ralf and Virtanen, Pauli and Cournapeau, David and Wieser, Eric and Taylor, Julian and Berg, Sebastian and Smith, Nathaniel J. and Kern, Robert and Picus, Matti and Hoyer, Stephan and van Kerkwijk, Marten H. and Brett, Matthew and Haldane, Allan and del R{\'i}o, Jaime Fern{\'a}ndez and Wiebe, Mark and Peterson, Pearu and G{\'e}rard-Marchant, Pierre and Sheppard, Kevin and Reddy, Tyler and Weckesser, Warren and Abbasi, Hameer and Gohlke, Christoph and Oliphant, Travis E.},
	year         = 2020,
	journal      = {Nature},
	volume       = 585,
	number       = 7825,
	pages        = {357--362}
}
@article{engel1992temporal,
	title        = {Temporal Coding in the Visual Cortex: New Vistas on Integration in the Nervous System},
	author       = {Engel, Andreas K and K{\"o}nig, Peter and Kreiter, Andreas K and Schillen, Thomas B and Singer, Wolf},
	year         = 1992,
	journal      = {Trends in Neurosciences},
	volume       = 15,
	number       = 6,
	pages        = {218--226}
}
@inproceedings{dong2017spike,
	title        = {Spike Camera and Its Coding Methods},
	author       = {Dong, Siwei and Huang, Tiejun and Tian, Yonghong},
	year         = 2017,
	booktitle    = {Data Compression Conference},
	pages        = {437--437},
	organization = {IEEE Computer Society}
}
@inproceedings{huang2017dynamic,
	title        = {A Dynamic Vision Sensor with Direct Logarithmic Output and Full-Frame Picture-on-Demand},
	author       = {Huang, Jing and Guo, Menghan and Chen, Shoushun},
	year         = 2017,
	booktitle    = {IEEE International Symposium on Circuits and Systems},
	pages        = {1--4},
	organization = {IEEE}
}
@inproceedings{ijcai2021-236,
	title        = {Pruning of Deep Spiking Neural Networks through Gradient Rewiring},
	author       = {Chen, Yanqi and Yu, Zhaofei and Fang, Wei and Huang, Tiejun and Tian, Yonghong},
	year         = 2021,
	booktitle    = {International Joint Conference on Artificial Intelligence},
	pages        = {1713--1721},
	doi          = {10.24963/ijcai.2021/236},
}
@inproceedings{ding2021optimal,
	title        = {Optimal ANN-SNN Conversion for Fast and Accurate Inference in Deep Spiking Neural Networks},
	author       = {Ding, Jianhao and Yu, Zhaofei and Tian, Yonghong and Huang, Tiejun},
	year         = 2021,
	booktitle    = {International Joint Conference on Artificial Intelligence},
	pages        = {2328--2336},
	doi          = {10.24963/ijcai.2021/321},
}
@article{kheradpisheh2022spiking,
	title        = {Spiking Neural Networks Trained via Proxy},
	author       = {Kheradpisheh, Saeed Reza and Mirsadeghi, Maryam and Masquelier, Timoth{\'e}e},
	year         = 2022,
	journal      = {IEEE Access}
}
@article{ranccon2021stereospike,
	title        = {StereoSpike: Depth Learning With a Spiking Neural Network},
	author       = {Rançon, Ulysse and Cuadrado-Anibarro, Javier and Cottereau, Benoit R. and Masquelier, Timothée},
	year         = 2022,
	journal      = {IEEE Access},
	volume       = 10,
	number       = {},
	pages        = {127428--127439},
	doi          = {10.1109/ACCESS.2022.3226484},
	keywords     = {Cameras;Task analysis;Neuromorphics;Computer vision;Computer architecture;Estimation;Biological neural networks;Deep learning;Neural networks;Computer vision;bio-inspired learning;deep neural architectures;neuromorphic computing;spiking neural networks;stereo depth regression}
}
@article{xiong2021odor,
	title        = {An Odor Recognition Algorithm of Electronic Noses Based on Convolutional Spiking Neural Network for Spoiled Food Identification},
	author       = {Xiong, Yizhou and Chen, Yuantao and Chen, Changming and Wei, Xinwei and Xue, Yingying and Wan, Hao and Wang, Ping},
	year         = 2021,
	journal      = {Journal of The Electrochemical Society},
	volume       = 168,
	number       = 7,
	pages        = {077519}
}
@article{han2021cascade,
	title        = {Cascade Spiking Neuron Network For Event-based Image Classification In Noisy Environment},
	author       = {Han, Yuntao and Yu, Tao and Cheng, Silu and Xu, Jiangtao},
	year         = 2021,
	journal      = {TechRxiv}
}
@article{vicente2021keys,
	title        = {Keys to Accurate Feature Extraction Using Residual Spiking Neural Networks},
	author       = {Alex Vicente-Sola and Davide L Manna and Paul Kirkland and Gaetano Di Caterina and Trevor Bihl},
	year         = 2022,
	journal      = {Neuromorphic Computing and Engineering},
	volume       = 2,
	number       = 4,
	pages        = {044001},
	doi          = {10.1088/2634-4386/ac8bef}
}
@article{chen2022deep,
	title        = {Deep Reinforcement Learning with Spiking Q-learning},
	author       = {Chen, Ding and Peng, Peixi and Huang, Tiejun and Tian, Yonghong},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2201.09754}
}
@article{liu2021human,
	title        = {Human-Level Control Through Directly Trained Deep Spiking Q-Networks},
	author       = {Liu, Guisong and Deng, Wenjie and Xie, Xiurui and Huang, Li and Tang, Huajin},
	year         = 2023,
	journal      = {IEEE Transactions on Cybernetics},
	volume       = 53,
	number       = 11,
	pages        = {7187--7198},
	doi          = {10.1109/TCYB.2022.3198259},
	keywords     = {Neurons;Games;Membrane potentials;Training;Biological neural networks;Q-learning;Neuromorphics;Atari games;deep reinforcement learning (DRL);directly training;spiking neural networks (SNNs)}
}
@inproceedings{zhu2022event,
	title        = {Event-based Video Reconstruction via Potential-assisted Spiking Neural Network},
	author       = {Zhu, Lin and Wang, Xiao and Chang, Yi and Li, Jianing and Huang, Tiejun and Tian, Yonghong},
	year         = 2022,
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {3594--3604}
}
@inproceedings{bu2021optimal,
	title        = {Optimal ANN-SNN Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks},
	author       = {Bu, Tong and Fang, Wei and Ding, Jianhao and Dai, PengLin and Yu, Zhaofei and Huang, Tiejun},
	year         = 2021,
	booktitle    = {International Conference on Learning Representations}
}
@inproceedings{bu2022optimized,
	title        = {Optimized Potential Initialization for Low-Latency Spiking Neural Networks},
	author       = {Bu, Tong and Ding, Jianhao and Yu, Zhaofei and Huang, Tiejun},
	year         = 2022,
	booktitle    = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume       = 36,
	number       = 1,
	pages        = {11--20},
	doi          = {10.1609/aaai.v36i1.19874}
}
@inproceedings{na2022autosnn,
	title        = {{A}uto{SNN}: Towards Energy-Efficient Spiking Neural Networks},
	author       = {Na, Byunggook and Mok, Jisoo and Park, Seongsik and Lee, Dongjin and Choe, Hyeokjun and Yoon, Sungroh},
	year         = 2022,
	booktitle    = {Proceedings of the 39th International Conference on Machine Learning},
	series       = {Proceedings of Machine Learning Research},
	volume       = 162,
	pages        = {16253--16269},
	pdf          = {https://proceedings.mlr.press/v162/na22a/na22a.pdf},
	abstract     = {Spiking neural networks (SNNs) that mimic information transmission in the brain can energy-efficiently process spatio-temporal information through discrete and sparse spikes, thereby receiving considerable attention. To improve accuracy and energy efficiency of SNNs, most previous studies have focused solely on training methods, and the effect of architecture has rarely been studied. We investigate the design choices used in the previous studies in terms of the accuracy and number of spikes and figure out that they are not best-suited for SNNs. To further improve the accuracy and reduce the spikes generated by SNNs, we propose a spike-aware neural architecture search framework called AutoSNN. We define a search space consisting of architectures without undesirable design choices. To enable the spike-aware architecture search, we introduce a fitness that considers both the accuracy and number of spikes. AutoSNN successfully searches for SNN architectures that outperform hand-crafted SNNs in accuracy and energy efficiency. We thoroughly demonstrate the effectiveness of AutoSNN on various datasets including neuromorphic datasets.}
}
@inproceedings{kim2022neural,
	title        = {Neural Architecture Search for Spiking Neural Networks},
	author       = {Kim, Youngeun and Li, Yuhang and Park, Hyoungseob and Venkatesha, Yeshwanth and Panda, Priyadarshini},
	year         = 2022,
	booktitle    = {European Conference on Computer Vision},
	address      = {Cham},
	pages        = {36--56},
	isbn         = {978-3-031-20053-3},
	abstract     = {Spiking Neural Networks (SNNs) have gained huge attention as a potential energy-efficient alternative to conventional Artificial Neural Networks (ANNs) due to their inherent high-sparsity activation. However, most prior SNN methods use ANN-like architectures (e.g., VGG-Net or ResNet), which could provide sub-optimal performance for temporal sequence processing of binary information in SNNs. To address this, in this paper, we introduce a novel Neural Architecture Search (NAS) approach for finding better SNN architectures. Inspired by recent NAS approaches that find the optimal architecture from activation patterns at initialization, we select the architecture that can represent diverse spike activation patterns across different data samples without training. Moreover, to further leverage the temporal information among the spikes, we search for feed-forward connections as well as backward connections (i.e., temporal feedback connections) between layers. Interestingly, SNASNet found by our search algorithm achieves higher performance with backward connections, demonstrating the importance of designing SNN architecture for suitably using temporal information. We conduct extensive experiments on three image recognition benchmarks where we show that SNASNet achieves state-of-the-art performance with significantly lower timesteps (5 timesteps). Code is available on Github.}
}
@inproceedings{li2021feas,
	title        = {FEAS: a Faster Event-driven Accelerator Supporting Inhibitory Spiking Neural Network},
	author       = {Li, Songsong and Gong, Lei and Wang, Teng and Wang, Chao and Zhou, Xuehai},
	year         = 2021,
	booktitle    = {International Symposium on Parallel Architectures, Algorithms and Programming},
	pages        = {14--18},
	organization = {IEEE}
}
@inproceedings{li2022neuromorphic,
	title        = {Neuromorphic Data Augmentation for Training Spiking Neural Networks},
	author       = {Li, Yuhang and Kim, Youngeun and Park, Hyoungseob and Geller, Tamar and Panda, Priyadarshini},
	year         = 2022,
	booktitle    = {European Conference on Computer Vision},
	address      = {Cham},
	pages        = {631--649},
	isbn         = {978-3-031-20071-7},
	abstract     = {Developing neuromorphic intelligence on event-based datasets with Spiking Neural Networks (SNNs) has recently attracted much research attention. However, the limited size of event-based datasets makes SNNs prone to overfitting and unstable convergence. This issue remains unexplored by previous academic works. In an effort to minimize this generalization gap, we propose Neuromorphic Data Augmentation (NDA), a family of geometric augmentations specifically designed for event-based datasets with the goal of significantly stabilizing the SNN training and reducing the generalization gap between training and test performance. The proposed method is simple and compatible with existing SNN training pipelines. Using the proposed augmentation, for the first time, we demonstrate the feasibility of unsupervised contrastive learning for SNNs. We conduct comprehensive experiments on prevailing neuromorphic vision benchmarks and show that NDA yields substantial improvements over previous state-of-the-art results. For example, the NDA-based SNN achieves accuracy gain on CIFAR10-DVS and N-Caltech 101 by 10.1{\%} and 13.7{\%}, respectively. Code is available on GitHub (URL).}
}
@article{jin2022sit,
	title        = {SIT: a Bionic and Non-Linear Neuron for Spiking Neural Network},
	author       = {Jin, Cheng and Zhu, Rui-Jie and Wu, Xiao and Deng, Liang-Jian},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2203.16117}
}
@article{feng2022building,
	title        = {Building and Training a Deep Spiking Neural Network for ECG classification},
	author       = {Feng, Yifei and Geng, Shijia and Chu, Jianjun and Fu, Zhaoji and Hong, Shenda},
	year         = 2022,
	journal      = {Biomedical Signal Processing and Control},
	volume       = 77,
	pages        = 103749
}
@inproceedings{liu2022dynsnn,
	title        = {DynSNN: a Dynamic Approach to Reduce Redundancy in Spiking Neural Networks},
	author       = {Liu, Fangxin and Zhao, Wenbo and Chen, Yongbiao and Wang, Zongwu and Dai, Fei},
	year         = 2022,
	booktitle    = {IEEE International Conference on Acoustics, Speech and Signal Processing},
	pages        = {2130--2134},
	organization = {IEEE}
}
@inproceedings{cordone2022object,
	title        = {Object Detection with Spiking Neural Networks on Automotive Event Data},
	author       = {Cordone, Loïc and Miramond, Benoît and Thierion, Philippe},
	year         = 2022,
	booktitle    = {International Joint Conference on Neural Networks},
	pages        = {1--8},
	doi          = {10.1109/IJCNN55064.2022.9892618},
	keywords     = {Deep learning;Power demand;Neurons;Object detection;Hardware;Energy efficiency;Encoding;spiking neural networks;event cameras;object detection;SSD}
}
@inproceedings{chen2022state,
	title        = {State Transition of Dendritic Spines Improves Learning of Sparse Spiking Neural Networks},
	author       = {Chen, Yanqi and Yu, Zhaofei and Fang, Wei and Ma, Zhengyu and Huang, Tiejun and Tian, Yonghong},
	year         = 2022,
	booktitle    = {International Conference on Machine Learning},
	pages        = {3701--3715},
	organization = {PMLR}
}
@inproceedings{meng2022training,
	title        = {Training High-Performance Low-Latency Spiking Neural Networks by Differentiation on Spike Representation},
	author       = {Meng, Qingyan and Xiao, Mingqing and Yan, Shen and Wang, Yisen and Lin, Zhouchen and Luo, Zhi-Quan},
	year         = 2022,
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {12444--12453}
}
@article{tang2022relaxation,
	title        = {Relaxation LIF: a Gradient-Based Spiking Neuron for Direct Training Deep Spiking Neural Networks},
	author       = {Tang, Jianxiong and Lai, Jian-Huang and Zheng, Wei-Shi and Yang, Lingxiao and Xie, Xiaohua},
	year         = 2022,
	journal      = {Neurocomputing},
	volume       = 501,
	pages        = {499--513}
}
@article{barchid2022spiking,
	title        = {Spiking Neural Networks for Frame-based and Event-Based Single Object Localization},
	author       = {Sami Barchid and José Mennesson and Jason Eshraghian and Chaabane Djéraba and Mohammed Bennamoun},
	year         = 2023,
	journal      = {Neurocomputing},
	volume       = 559,
	pages        = 126805,
	doi          = {https://doi.org/10.1016/j.neucom.2023.126805},
	issn         = {0925-2312},
	keywords     = {Spiking neural network, Object localization, Event-based camera, Neural coding scheme, Surrogate gradient learning},
	abstract     = {Spiking neural networks (SNNs) have shown much promise as an energy-efficient alternative to artificial neural networks (ANNs). Such methods trained by surrogate gradient (SG) descent are now capable of dealing with frame- or event-based vision tasks beyond classification (e.g. object detection, semantic segmentation). However, important questions about their behavior w.r.t fundamental design choices remain under-explored (e.g. how a specific neural coding scheme impacts the performance/robustness? Does a higher temporal latency necessarily imply better results?). In this paper, we focus on single object localization as a context to analyze deep convolutional SNNs on (1) the importance of temporal latency (i.e. the number of time-steps) on performance ; (2) their robustness against sensor corruptions ; and (3) the impact of neural coding schemes on performance with static images. We design a simple SNN baseline for frame- and event-based single object localization and compare it against a similar ANN architecture. Our experiments show that our approach can achieve competitive or better performance in accuracy and robustness against common sensor corruptions with significantly lower energy consumption. More importantly, our experimental analysis draws conclusions significantly different from well-known studies focused on SNNs trained with bio-plausible learning rules, which helps in the design of SG-trained architectures, and offers insight to design priorities in future neuromorphic technologies.}
}
@article{zhu2022tcja,
	title        = {TCJA-SNN: Temporal-Channel Joint Attention for Spiking Neural Networks},
	author       = {Zhu, Rui-Jie and Zhang, Malu and Zhao, Qihang and Deng, Haoyu and Duan, Yule and Deng, Liang-Jian},
	year         = 2024,
	journal      = {IEEE Transactions on Neural Networks and Learning Systems},
	pages        = {1--14},
	doi          = {10.1109/TNNLS.2024.3377717},
	keywords     = {Task analysis;Neurons;Training;Correlation;Biological system modeling;Biological neural networks;Spatiotemporal phenomena;Attention mechanism;neuromorphic datasets;spatiotemporal information;spiking neural networks (SNNs)}
}
@inproceedings{kim2022lottery,
	title        = {Exploring Lottery Ticket Hypothesis in Spiking Neural Networks},
	author       = {Kim, Youngeun and Li, Yuhang and Park, Hyoungseob and Venkatesha, Yeshwanth and Yin, Ruokai and Panda, Priyadarshini},
	year         = 2022,
	booktitle    = {European Conference on Computer Vision},
	address      = {Cham},
	pages        = {102--120},
	isbn         = {978-3-031-19775-8},
	abstract     = {Spiking Neural Networks (SNNs) have recently emerged as a new generation of low-power deep neural networks, which is suitable to be implemented on low-power mobile/edge devices. As such devices have limited memory storage, neural pruning on SNNs has been widely explored in recent years. Most existing SNN pruning works focus on shallow SNNs (2--6 layers), however, deeper SNNs ({\$}{\$}{\backslash}ge {\$}{\$}≥16 layers) are proposed by state-of-the-art SNN works, which is difficult to be compatible with the current SNN pruning work. To scale up a pruning technique towards deep SNNs, we investigate Lottery Ticket Hypothesis (LTH) which states that dense networks contain smaller subnetworks (i.e., winning tickets) that achieve comparable performance to the dense networks. Our studies on LTH reveal that the winning tickets consistently exist in deep SNNs across various datasets and architectures, providing up to {\$}{\$}97{\backslash}{\%}{\$}{\$}97{\%}sparsity without huge performance degradation. However, the iterative searching process of LTH brings a huge training computational cost when combined with the multiple timesteps of SNNs. To alleviate such heavy searching cost, we propose Early-Time (ET) ticket where we find the important weight connectivity from a smaller number of timesteps. The proposed ET ticket can be seamlessly combined with a common pruning techniques for finding winning tickets, such as Iterative Magnitude Pruning (IMP) and Early-Bird (EB) tickets. Our experiment results show that the proposed ET ticket reduces search time by up to {\$}{\$}38{\backslash}{\%}{\$}{\$}38{\%}compared to IMP or EB methods. Code is available at Github.}
}
@article{tang2022snn2ann,
	title        = {SNN2ANN: a Fast and Memory-Efficient Training Framework for Spiking Neural Networks},
	author       = {Tang, Jianxiong and Lai, Jianhuang and Xie, Xiaohua and Yang, Lingxiao and Zheng, Wei-Shi},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2206.09449}
}
@book{Goodfellow-et-al-2016,
	title        = {Deep Learning},
	author       = {Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
	year         = 2016
}
@inproceedings{https://doi.org/10.48550/arxiv.2110.00476,
	title        = {ResNet Strikes Back: an Improved Training Procedure in Timm},
	author       = {Ross Wightman and Hugo Touvron and Herve Jegou},
	year         = 2021,
	booktitle    = {NeurIPS 2021 Workshop on ImageNet: Past, Present, and Future}
}
@article{yuan2022calibratable,
	title        = {A Calibratable Sensory Neuron Based on Epitaxial VO2 for Spike-based Neuromorphic Multisensory System},
	author       = {Yuan, Rui and Duan, Qingxi and Tiw, Pek Jun and Li, Ge and Xiao, Zhuojian and Jing, Zhaokun and Yang, Ke and Liu, Chang and Ge, Chen and Huang, Ru and Yang, Yuchao},
	year         = 2022,
	journal      = {Nature Communications},
	volume       = 13,
	number       = 1,
	pages        = {1--12}
}
@article{doi:10.1063/5.0096643,
	title        = {A Model of TaOx Threshold Switching Memristor for Neuromorphic Computing},
	author       = {Li,Xing  and Feng,Zhe  and Zou,Jianxun  and Wang,Xu  and Hu,Guyue  and Wang,Feifei  and Ding,Cheng  and Zhu,Yunlai  and Yang,Fei  and Wu,Zuheng  and Dai,Yuehua},
	year         = 2022,
	journal      = {Journal of Applied Physics},
	volume       = 132,
	number       = 6,
	pages        = {064904},
	doi          = {10.1063/5.0096643}
}
@article{roy2019towards,
	title        = {Towards Spike-based Machine Intelligence with Neuromorphic Computing},
	author       = {Roy, Kaushik and Jaiswal, Akhilesh and Panda, Priyadarshini},
	year         = 2019,
	journal      = {Nature},
	volume       = 575,
	number       = 7784,
	pages        = {607--617}
}
@article{gollisch2008rapid,
	title        = {Rapid Neural Coding in the Retina with Relative Spike Latencies},
	author       = {Gollisch, Tim and Meister, Markus},
	year         = 2008,
	journal      = {Science},
	volume       = 319,
	number       = 5866,
	pages        = {1108--1111}
}
@article{wu2022brain,
	title        = {Brain-Inspired Global-Local Learning Incorporated with Neuromorphic Computing},
	author       = {Wu, Yujie and Zhao, Rong and Zhu, Jun and Chen, Feng and Xu, Mingkun and Li, Guoqi and Song, Sen and Deng, Lei and Wang, Guanrui and Zheng, Hao and Ma, Songchen and Pei, Jing and Zhang, Youhui and Zhao, Mingguo and Shi, Luping},
	year         = 2022,
	journal      = {Nature Communications},
	volume       = 13,
	number       = 1,
	pages        = {1--14}
}
@article{kim2018deep,
	title        = {Deep Neural Networks with Weighted Spikes},
	author       = {Kim, Jaehyun and Kim, Heesu and Huh, Subin and Lee, Jinho and Choi, Kiyoung},
	year         = 2018,
	journal      = {Neurocomputing},
	volume       = 311,
	pages        = {373--386}
}
@article{hassabis2017neuroscience,
	title        = {Neuroscience-inspired Artificial Intelligence},
	author       = {Hassabis, Demis and Kumaran, Dharshan and Summerfield, Christopher and Botvinick, Matthew},
	year         = 2017,
	journal      = {Neuron},
	volume       = 95,
	number       = 2,
	pages        = {245--258}
}
@article{rosenblatt1958perceptron,
	title        = {The Perceptron: a Probabilistic Model for Information Storage and Organization in the Brain},
	author       = {Rosenblatt, Frank},
	year         = 1958,
	journal      = {Psychological Review},
	volume       = 65,
	number       = 6,
	pages        = 386
}
@article{cox2014neural,
	title        = {Neural Networks and Neuroscienc-inspired Computer Vision},
	author       = {Cox, David Daniel and Dean, Thomas},
	year         = 2014,
	journal      = {Current Biology},
	volume       = 24,
	number       = 18,
	pages        = {R921--R929}
}
@inproceedings{nabavinejad2021batchsizer,
	title        = {BatchSizer: Power-performance trade-off for DNN inference},
	author       = {Nabavinejad, Seyed Morteza and Reda, Sherief and Ebrahimi, Masoumeh},
	year         = 2021,
	booktitle    = {Proceedings of the 26th Asia and South Pacific Design Automation Conference},
	pages        = {819--824}
}
@article{taherkhani2020review,
	title        = {A Review of Learning in Biologically Plausible Spiking Neural Networks},
	author       = {Taherkhani, Aboozar and Belatreche, Ammar and Li, Yuhua and Cosma, Georgina and Maguire, Liam P and McGinnity, T Martin},
	year         = 2020,
	journal      = {Neural Networks},
	volume       = 122,
	pages        = {253--272}
}
@inproceedings{8595219,
	title        = {The Open-Closed Principle of Modern Machine Learning Frameworks},
	author       = {Ben Braiek, Houssem and Khomh, Foutse and Adams, Bram},
	year         = 2018,
	booktitle    = {IEEE/ACM 15th International Conference on Mining Software Repositories},
	pages        = {353--363}
}
@inproceedings{abadi2016tensorflow,
	title        = {TensorFlow: a System for Large-Scale Machine Learning},
	author       = {Abadi, Mart\'{\i}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and Kudlur, Manjunath and Levenberg, Josh and Monga, Rajat and Moore, Sherry and Murray, Derek G. and Steiner, Benoit and Tucker, Paul and Vasudevan, Vijay and Warden, Pete and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
	year         = 2016,
	booktitle    = {12th USENIX Symposium on Operating Systems Design and Implementation},
	pages        = {265--283}
}
@misc{chollet2015keras,
	title        = {Keras},
	author       = {Chollet, Fran\c{c}ois and others},
	year         = 2015
}
@article{goertzel2014artificial,
	title        = {Artificial General Intelligence: Concept, State of the Art, and Future Prospects},
	author       = {Goertzel, Ben},
	year         = 2014,
	journal      = {Journal of Artificial General Intelligence},
	volume       = 5,
	number       = 1,
	pages        = 1
}
@article{srivastava2014dropout,
	title        = {Dropout: a Simple Way to Prevent Neural Networks from Overfitting},
	author       = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
	year         = 2014,
	journal      = {The Journal of Machine Learning Research},
	volume       = 15,
	number       = 1,
	pages        = {1929--1958}
}
@article{chen2014big,
	title        = {Big Data Deep Learning: Challenges and Perspectives},
	author       = {Chen, Xue-Wen and Lin, Xiaotong},
	year         = 2014,
	journal      = {IEEE Access},
	volume       = 2,
	pages        = {514--525}
}
@inproceedings{raina2009large,
	title        = {Large-scale Deep Unsupervised Learning Using Graphics Processors},
	author       = {Raina, Rajat and Madhavan, Anand and Ng, Andrew Y},
	year         = 2009,
	booktitle    = {International Conference on Machine Learning},
	pages        = {873--880}
}

@inproceedings{NIPS2012_c399862d,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 volume = {25},
 year = {2012}
}



@article{rumelhart1986learning,
	title        = {Learning Representations by Back-Propagating Errors},
	author       = {Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
	year         = 1986,
	journal      = {Nature},
	volume       = 323,
	number       = 6088,
	pages        = {533--536}
}
@inproceedings{kingma2014adam,
	title        = {Adam: a Method for Stochastic Optimization},
	author       = {Diederik P. Kingma and Jimmy Ba},
	year         = 2015,
	booktitle    = {International Conference on Learning Representations},
	timestamp    = {Thu, 25 Jul 2019 14:25:37 +0200},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{hubel1959receptive,
	title        = {Receptive Fields of Single Neurones in the Cat's Striate Cortex},
	author       = {Hubel, David H and Wiesel, Torsten N},
	year         = 1959,
	journal      = {The Journal of Physiology},
	volume       = 148,
	number       = 3,
	pages        = 574
}
@article{lecun1989generalization,
	title        = {Generalization and Network Design Strategies},
	author       = {LeCun, Yann},
	year         = 1989,
	journal      = {Connectionism in Perspective},
	volume       = 19,
	number       = {143-155},
	pages        = 18
}
@inproceedings{larochelle2010learning,
	title        = {Learning to Combine Foveal Glimpses with a Third-Order Boltzmann Machine},
	author       = {Larochelle, Hugo and Hinton, Geoffrey E},
	year         = 2010,
	booktitle    = {Advances in Neural Information Processing Systems},
	volume       = 23
}
@article{denil2012learning,
	title        = {Learning Where to Attend with Deep Architectures for Image Tracking},
	author       = {Denil, Misha and Bazzani, Loris and Larochelle, Hugo and de Freitas, Nando},
	year         = 2012,
	journal      = {Neural Computation},
	volume       = 24,
	number       = 8,
	pages        = {2151--2184}
}
@incollection{koch1987shifts,
	title        = {Shifts in Selective Visual Attention: Towards the Underlying Neural Circuitry},
	author       = {Koch, Christof and Ullman, Shimon},
	year         = 1987,
	booktitle    = {Matters of Intelligence},
	pages        = {115--141}
}
@article{posner1990attention,
	title        = {The Attention System of the Human Brain},
	author       = {Posner, Michael I and Petersen, Steven E},
	year         = 1990,
	journal      = {Annual Review of Neuroscience},
	volume       = 13,
	number       = 1,
	pages        = {25--42}
}
@article{hochreiter1997long,
	title        = {Long Short-Term Memory},
	author       = {Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
	year         = 1997,
	journal      = {Neural Computation},
	volume       = 9,
	number       = 8,
	pages        = {1735--1780}
}
@article{chung2014empirical,
	title        = {Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling},
	author       = {Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua},
	year         = 2014,
	journal      = {arXiv preprint arXiv:1412.3555}
}
@inproceedings{kim2020spiking,
	title        = {Spiking-YOLO: Spiking Neural Network for Energy-Efficient Object Detection},
	author       = {Kim, Seijoon and Park, Seongsik and Na, Byunggook and Yoon, Sungroh},
	year         = 2020,
	booktitle    = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume       = 34,
	number       = {07},
	pages        = {11270--11277}
}
@article{patel2021spiking,
	title        = {A Spiking Neural Network for Image Segmentation},
	author       = {Patel, Kinjal and Hunsberger, Eric and Batir, Sean and Eliasmith, Chris},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2106.08921}
}
@inproceedings{parameshwara2021spikems,
	title        = {SpikeMS: Deep Spiking Neural Network for Motion Segmentation},
	author       = {Parameshwara, Chethan M and Li, Simin and Ferm{\"u}ller, Cornelia and Sanket, Nitin J and Evanusa, Matthew S and Aloimonos, Yiannis},
	year         = 2021,
	booktitle    = {IEEE/RSJ International Conference on Intelligent Robots and Systems},
	pages        = {3414--3420},
	organization = {IEEE}
}
@inproceedings{lee2020spike,
	title        = {Spike-FlowNet: Event-Based Optical Flow Estimation with Energy-Efficient Hybrid Neural Networks},
	author       = {Lee, Chankyu and Kosta, Adarsh Kumar and Zhu, Alex Zihao and Chaney, Kenneth and Daniilidis, Kostas and Roy, Kaushik},
	year         = 2020,
	booktitle    = {European Conference on Computer Vision},
	pages        = {366--382},
	organization = {Springer}
}

@article{1606.01540,
	title={OpenAI Gym},
	author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
	journal={arXiv preprint arXiv:1606.01540},
	year={2016}
}


@article{Masquelier2007,
	title        = {Unsupervised Learning of Visual Features through Spike Timing Dependent Plasticity},
	author       = {Masquelier, Timoth{\'{e}}e and Thorpe, Simon J},
	year         = 2007,
	journal      = {PLOS Computational Biology},
	volume       = 3,
	number       = 2,
	pages        = {e31},
	doi          = {10.1371/journal.pcbi.0030031},
	pmid         = 17305422
}
@article{Kheradpisheh2018,
	title        = {STDP-Based Spiking Deep Convolutional Neural Networks for Object Recognition},
	author       = {Kheradpisheh, Saeed Reza and Ganjtabesh, Mohammad and Thorpe, Simon J and Masquelier, Timoth{\'{e}}e},
	year         = 2018,
	journal      = {Neural Networks},
	volume       = 99,
	pages        = {56--67},
	doi          = {10.1016/j.neunet.2017.12.005},
	issn         = {08936080},
	pmid         = 29328958
}
@article{morrison2008phenomenological,
	title        = {Phenomenological Models of Synaptic Plasticity Based on Spike Timing},
	author       = {Morrison, Abigail and Diesmann, Markus and Gerstner, Wulfram},
	year         = 2008,
	journal      = {Biological Cybernetics},
	volume       = 98,
	pages        = {459--478}
}
@inproceedings{wang2022hardvs,
	title        = {HARDVS: Revisiting Human Activity Recognition with Dynamic Vision Sensors},
	author       = {Wang, Xiao and Wu, Zongzhen and Jiang, Bo and Bao, Zhimin and Zhu, Lin and Li, Guoqi and Wang, Yaowei and Tian, Yonghong},
	year         = 2024,
	journal      = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume       = 38,
	number       = 6,
	pages        = {5615--5623},
	doi          = {10.1609/aaai.v38i6.28372},
	abstractnote = {The main streams of human activity recognition (HAR) algorithms are developed based on RGB cameras which usually suffer from illumination, fast motion, privacy preservation, and large energy consumption. Meanwhile, the biologically inspired event cameras attracted great interest due to their unique features, such as high dynamic range, dense temporal but sparse spatial resolution, low latency, low power, etc. As it is a newly arising sensor, even there is no realistic large-scale dataset for HAR. Considering its great practical value, in this paper, we propose a large-scale benchmark dataset to bridge this gap, termed HARDVS, which contains 300 categories and more than 100K event sequences. We evaluate and report the performance of multiple popular HAR algorithms, which provide extensive baselines for future works to compare. More importantly, we propose a novel spatial-temporal feature learning and fusion framework, termed ESTF, for event stream based human activity recognition. It first projects the event streams into spatial and temporal embeddings using StemNet, then, encodes and fuses the dual-view representations using Transformer networks. Finally, the dual features are concatenated and fed into a classification head for activity prediction. Extensive experiments on multiple datasets fully validated the effectiveness of our model. Both the dataset and source code will be released at https://github.com/Event-AHU/HARDVS.}
}
@article{yin2023accurate,
	title        = {Accurate Online Training of Dynamical Spiking Neural Networks through Forward Propagation through Time},
	author       = {Yin, Bojian and Corradi, Federico and Boht{\'e}, Sander M},
	year         = 2023,
	journal      = {Nature Machine Intelligence},
	pages        = {1--10}
}
@inproceedings{pmlr-v139-kag21a,
	title        = {Training Recurrent Neural Networks via Forward Propagation Through Time},
	author       = {Kag, Anil and Saligrama, Venkatesh},
	year         = 2021,
	booktitle    = {International Conference on Machine Learning},
	series       = {Proceedings of Machine Learning Research},
	volume       = 139,
	pages        = {5189--5200},
	pdf          = {http://proceedings.mlr.press/v139/kag21a/kag21a.pdf},
	abstract     = {Back-propagation through time (BPTT) has been widely used for training Recurrent Neural Networks (RNNs). BPTT updates RNN parameters on an instance by back-propagating the error in time over the entire sequence length, and as a result, leads to poor trainability due to the well-known gradient explosion/decay phenomena. While a number of prior works have proposed to mitigate vanishing/explosion effect through careful RNN architecture design, these RNN variants still train with BPTT. We propose a novel forward-propagation algorithm, FPTT, where at each time, for an instance, we update RNN parameters by optimizing an instantaneous risk function. Our proposed risk is a regularization penalty at time $t$ that evolves dynamically based on previously observed losses, and allows for RNN parameter updates to converge to a stationary solution of the empirical RNN objective. We consider both sequence-to-sequence as well as terminal loss problems. Empirically FPTT outperforms BPTT on a number of well-known benchmark tasks, thus enabling architectures like LSTMs to solve long range dependencies problems.}
}
@article{florian2007reinforcement,
	title        = {Reinforcement Learning through Modulation of Spike-timing-Dependent Synaptic Plasticity},
	author       = {Florian, R{\u{a}}zvan V},
	year         = 2007,
	journal      = {Neural Computation},
	volume       = 19,
	number       = 6,
	pages        = {1468--1502}
}
@inproceedings{liu2020effective,
	title        = {Effective AER Object Classification Using Segmented Probability-Maximization Learning in Spiking Neural Networks},
	author       = {Liu, Qianhui and Ruan, Haibo and Xing, Dong and Tang, Huajin and Pan, Gang},
	year         = 2020,
	booktitle    = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume       = 34,
	number       = {02},
	pages        = {1308--1315}
}
@article{8891738,
	title        = {An Event-Driven Categorization Model for AER Image Sensors Using Multispike Encoding and Learning},
	author       = {Xiao, Rong and Tang, Huajin and Ma, Yuhao and Yan, Rui and Orchard, Garrick},
	year         = 2020,
	journal      = {IEEE Transactions on Neural Networks and Learning Systems},
	volume       = 31,
	number       = 9,
	pages        = {3649--3657},
	doi          = {10.1109/TNNLS.2019.2945630}
}
@article{zhu2023spikegpt,
	title        = {SpikeGPT: Generative Pre-trained Language Model with Spiking Neural Networks},
	author       = {Zhu, Rui-Jie and Zhao, Qihang and Eshraghian, Jason K},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2302.13939}
}
@inproceedings{abad2023sneaky,
	title        = {Sneaky Spikes: Uncovering Stealthy Backdoor Attacks in Spiking Neural Networks with Neuromorphic Data},
	author       = {Abad, Gorka and Ersoy, Oguzhan and Picek, Stjepan and Urbieta, Aitor},
	year         = 2024,
	booktitle    = {Network and Distributed System Security Symposium}
}
@inproceedings{abad2022poster,
	title        = {Poster: Backdoor Attacks on Spiking NNs and Neuromorphic Datasets},
	author       = {Abad, Gorka and Ersoy, Oguzhan and Picek, Stjepan and Ram{\'\i}rez-Dur{\'a}n, V{\'\i}ctor Julio and Urbieta, Aitor},
	year         = 2022,
	booktitle    = {Proceedings of the ACM SIGSAC Conference on Computer and Communications Security},
	pages        = {3315--3317}
}
@article{cuadrado2023optical,
	title        = {Optical Flow Estimation from Event-Based Cameras and Spiking Neural Networks},
	author       = {Cuadrado, Javier  and Rançon, Ulysse  and Cottereau, Benoit R.  and Barranco, Francisco  and Masquelier, Timothée},
	year         = 2023,
	journal      = {Frontiers in Neuroscience},
	volume       = 17,
	doi          = {10.3389/fnins.2023.1160034},
	issn         = {1662-453X}
}
@inproceedings{Yao_2021_ICCV,
	title        = {Temporal-Wise Attention Spiking Neural Networks for Event Streams Classification},
	author       = {Yao, Man and Gao, Huanhuan and Zhao, Guangshe and Wang, Dingheng and Lin, Yihan and Yang, Zhaoxu and Li, Guoqi},
	year         = 2021,
	booktitle    = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages        = {10221--10230}
}
@article{hammouamri2022mitigating,
	title        = {Mitigating Catastrophic Forgetting in Spiking Neural Networks through Threshold Modulation},
	author       = {Ilyass Hammouamri and Timoth{\'e}e Masquelier and Dennis George Wilson},
	year         = 2022,
	journal      = {Transactions on Machine Learning Research},
	issn         = {2835-8856}
}
@article{brainsci13020168,
	title        = {Supervised Learning Algorithm Based on Spike Train Inner Product for Deep Spiking Neural Networks},
	author       = {Lin, Xianghong and Zhang, Zhen and Zheng, Donghao},
	year         = 2023,
	journal      = {Brain Sciences},
	volume       = 13,
	number       = 2,
	doi          = {10.3390/brainsci13020168},
	issn         = {2076-3425}
}
@article{10005101,
	title        = {Surrogate-Assisted Cooperative Co-evolutionary Reservoir Architecture Search for Liquid State Machines},
	author       = {Zhou, Yan and Jin, Yaochu and Sun, Yao and Ding, Jinliang},
	year         = 2023,
	journal      = {IEEE Transactions on Emerging Topics in Computational Intelligence},
	pages        = {1--15},
	doi          = {10.1109/TETCI.2022.3228538}
}
@article{WANG2023109102,
	title        = {Bioinspired Membrane Learnable Spiking Neural Network for Autonomous Vehicle Sensors Fault Diagnosis under Open Environments},
	author       = {Huan Wang and Yan-Fu Li},
	year         = 2023,
	journal      = {Reliability Engineering \& System Safety},
	volume       = 233,
	pages        = 109102,
	doi          = {https://doi.org/10.1016/j.ress.2023.109102},
	issn         = {0951-8320},
	keywords     = {Fault diagnosis, Health status prediction, Spiking neural network, Autonomous vehicle sensors},
	abstract     = {Autonomous vehicles have successfully driven autonomously on urban roads, relying on numerous sensors for environmental perception and vehicle control. However, the abnormality and degradation of sensors will make vehicles face serious safety risks. Therefore, autonomous vehicles must have complete sensor fault diagnosis systems to detect anomalies and avoid accidents. Therefore, this paper explores brain-inspired spiking neural networks (SNN) for sensor fault diagnosis. Specifically, this paper proposes a brain-inspired membrane learnable residual spiking neural network (MLR-SNN) for sensor fault and health index prediction. SNN accurately simulates the dynamic mechanism of biological neurons and exhibits excellent spatiotemporal information processing potential and low power consumption while being highly biologically credible. Based on the convolution topology, this study designs a spike-residual-based SNN framework that optimizes the gradient transfer efficiency to enable deep-level spiking information encoding. In addition, membrane-learnable mechanisms are introduced to simulate the differences of neuronal membrane-related parameters in brains, which can better characterize the dynamics of neurons. The proposed MLR-SNN is validated on actual autonomous vehicle sensor datasets. Experimental results show that MLR-SNN with neural dynamics mechanism has excellent performance, and it can accurately predict fault mode and health index from multivariate sensor data under open environments.}
}
@article{kaiser2023neuromorphic,
	title        = {Neuromorphic-P2M: Processing-In-Pixel-In-Memory Paradigm for Neuromorphic Image Sensors},
	author       = {Kaiser, Md Abdullah-Al and Datta, Gourav and Wang, Zixu and Jacob, Ajey P. and Beerel, Peter A. and Jaiswal, Akhilesh R.},
	year         = 2023,
	journal      = {Frontiers in Neuroinformatics},
	volume       = 17,
	doi          = {10.3389/fninf.2023.1144301},
	issn         = {1662-5196}
}
@article{wu4179879dynamic,
	title        = {Dynamic Threshold Integrate and Fire Neuron Model for Low Latency Spiking Neural Networks},
	author       = {Xiyan Wu and Yufei Zhao and Yong Song and Yurong Jiang and Yashuo Bai and Xinyi Li and Ya Zhou and Xin Yang and Qun Hao},
	year         = 2023,
	journal      = {Neurocomputing},
	volume       = 544,
	pages        = 126247,
	doi          = {https://doi.org/10.1016/j.neucom.2023.126247},
	issn         = {0925-2312},
	keywords     = {Spiking neural networks, ANN-to-SNN conversion, Threshold variability, Image classification}
}
@article{electronics11121889,
	title        = {Accurate ECG Classification Based on Spiking Neural Network and Attentional Mechanism for Real-Time Implementation on Personal Portable Devices},
	author       = {Xing, Yuxuan and Zhang, Lei and Hou, Zhixian and Li, Xiaoran and Shi, Yueting and Yuan, Yiyang and Zhang, Feng and Liang, Sen and Li, Zhenzhong and Yan, Liang},
	year         = 2022,
	journal      = {Electronics},
	volume       = 11,
	number       = 12,
	doi          = {10.3390/electronics11121889},
	issn         = {2079-9292},
	article-number = 1889
}
@article{D2NR06498G,
	title        = {Control and Regulation of Skyrmionic Topological Charge in a Novel Synthetic Antiferromagnetic Nanostructure},
	author       = {Gong, Bin and Wei, Chenhuinan and Yang, Han and Yu, Ziyang and Wang, Luowen and Xiong, Lun and Xiong, Rui and Lu, Zhihong and Zhang, Yue and Liu, Qingbo},
	year         = 2023,
	journal      = {Nanoscale},
	doi          = {10.1039/D2NR06498G}
}
@article{9994622,
	title        = {Deep Spiking Residual Shrinkage Network for Bearing Fault Diagnosis},
	author       = {Xu, Zongtang and Ma, Yumei and Pan, Zhenkuan and Zheng, Xiaoyang},
	year         = 2022,
	journal      = {IEEE Transactions on Cybernetics},
	pages        = {1--6},
	doi          = {10.1109/TCYB.2022.3227363}
}
@article{ZHAN2023110193,
	title        = {Bio-Inspired Active Learning Method in Spiking Neural Network},
	author       = {Qiugang Zhan and Guisong Liu and Xiurui Xie and Malu Zhang and Guolin Sun},
	year         = 2023,
	journal      = {Knowledge-Based Systems},
	volume       = 261,
	pages        = 110193,
	doi          = {https://doi.org/10.1016/j.knosys.2022.110193},
	issn         = {0950-7051},
	keywords     = {Spiking neural networks, Active learning, Bio-inspired behavior patterns},
	abstract     = {Spiking neural networks (SNNs) have gained a lot of attention and achievements recently because of their low-power advantages on neuromorphic hardware. However, training deep SNNs still requires a large number of labeled data which are expensive to obtain. To address this issue, we propose an effective Bio-inspired Active Learning (BAL) method in this paper to reduce the training cost of SNN models. Specifically, bio-inspired behavior patterns of spiking neurons are defined to represent the internal states of SNN models for active learning. Then, an active learning sample selection strategy is proposed by leveraging the empirical and generalization pattern divergence in SNNs. By labeling selected samples and adding them to training, behavioral patterns can be optimized to improve the performance of neural networks. Comprehensive experiments are conducted on the CIFAR-10, SVHN, and Fashion-MNIST datasets with various sample proportions. The experimental results demonstrate that the proposed BAL achieves state-of-the-arts performance in SNNs compared with the existing active learning methods.}
}
@article{wang2022spiking,
	title        = {Spiking Emotions: Dynamic Vision Emotion Recognition Using Spiking Neural Networks},
	author       = {Wang, Binqiang and Dong, Gang and Zhao, Yaqian and Li, Rengang and Yang, Hongbin and Yin, Wenfeng and Liang, Lingyan},
	year         = 2022,
	journal      = {International Conference on Algorithms, High Performance Computing and Artificial Intelligence}
}
@inproceedings{10.1007/978-3-031-14903-0_5,
	title        = {Spiking Neuron Network Based on VTEAM Memristor and MOSFET-LIF Neuron},
	author       = {Fu, Jiahui and Gou, Shuiping and Guo, Zhang},
	year         = 2022,
	booktitle    = {Intelligence Science IV},
	address      = {Cham},
	pages        = {37--44},
	isbn         = {978-3-031-14903-0},
	abstract     = {Neuromorphic computing has been widely developed due to its low power consumption and powerful interpretability. LIF neurons, the general-purpose neurons in neuromorphic computing, are under constant research in hardware implementations of spiking neural networks. In this paper, we design a LIF circuit with MOSFET based on the mathematical model of the LIF neuron. The simulated circuit can be directly applied to the spiking neural network through the VTEAM memristor crossbar architecture. The effect of parameter changes in the circuit on the membrane potential is demonstrated. Finally, we validate feasibility of the process on the DVS128 gesture dataset using a generic spiking neural network architecture and obtain satisfactory performance.}
}
@inproceedings{lucas2022entrenamiento,
	title        = {Entrenamiento Supervisado De Redes Neuronales De Impulsos},
	author       = {Lucas, Sergio and Portillo, Eva and Zubizarreta, Asier and Cabanes, Itziar},
	year         = 2022,
	booktitle    = {XLIII Jornadas de Autom{\'a}tica},
	pages        = {216--223},
	organization = {Universidade da Coru{\~n}a. Servizo de Publicaci{\'o}ns}
}
@inproceedings{qin2022low,
	title        = {A Low Latency Adaptive Coding Spike Framework for Deep Reinforcement Learning},
	author       = {Qin, Lang and Yan, Rui and Tang, Huajin},
	year         = 2023,
	booktitle    = {International Joint Conference on Artificial Intelligence},
	pages        = {3049--3057},
	doi          = {10.24963/ijcai.2023/340},
}
@article{li2022spikeformer,
	title        = {Spikeformer: a Novel Architecture for Training High-Performance Low-Latency Spiking Neural Network},
	author       = {Li, Yudong and Lei, Yunlin and Yang, Xu},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2211.10686}
}
@inproceedings{lemaire2022analytical,
	title        = {An Analytical Estimation of Spiking Neural Networks Energy Efficiency},
	author       = {Lemaire, Edgar and Cordone, Lo{\"i}c and Castagnetti, Andrea and Novac, Pierre-Emmanuel and Courtois, Jonathan and Miramond, Beno{\^i}t},
	year         = 2023,
	booktitle    = {Neural Information Processing},
	address      = {Cham},
	pages        = {574--587},
	isbn         = {978-3-031-30105-6},
	abstract     = {Spiking Neural Networks are a type of neural networks where neurons communicate using only spikes. They are often presented as a low-power alternative to classical neural networks, but few works have proven these claims to be true. In this work, we present a metric to estimate the energy consumption of SNNs independently of a specific hardware. We then apply this metric on SNNs processing three different data types (static, dynamic and event-based) representative of real-world applications. As a result, all of our SNNs are 6 to 8 times more efficient than their FNN counterparts.}
}
@article{wu2022mss,
	title        = {MSS-DepthNet: Depth Prediction with Multi-Step Spiking Neural Network},
	author       = {Wu, Xiaoshan and He, Weihua and Yao, Man and Zhang, Ziyang and Wang, Yaoyuan and Li, Guoqi},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2211.12156}
}
@inproceedings{hao2023reducing,
	title        = {Reducing ANN-SNN Conversion Error through Residual Membrane Potential},
	author       = {Hao, Zecheng and Bu, Tong and Ding, Jianhao and Huang, Tiejun and Yu, Zhaofei},
	year         = 2023,
	journal      = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume       = 37,
	number       = 1,
	pages        = {11--21},
	doi          = {10.1609/aaai.v37i1.25071},
	abstractnote = {Spiking Neural Networks (SNNs) have received extensive academic attention due to the unique properties of low power consumption and high-speed computing on neuromorphic chips. Among various training methods of SNNs, ANN-SNN conversion has shown the equivalent level of performance as ANNs on large-scale datasets. However, unevenness error, which refers to the deviation caused by different temporal sequences of spike arrival on activation layers, has not been effectively resolved and seriously suffers the performance of SNNs under the condition of short time-steps. In this paper, we make a detailed analysis of unevenness error and divide it into four categories. We point out that the case of the ANN output being zero while the SNN output being larger than zero accounts for the largest percentage. Based on this, we theoretically prove the sufficient and necessary conditions of this case and propose an optimization strategy based on residual membrane potential to reduce unevenness error. The experimental results show that the proposed method achieves state-of-the-art performance on CIFAR-10, CIFAR-100, and ImageNet datasets. For example, we reach top-1 accuracy of 64.32% on ImageNet with 10-steps. To the best of our knowledge, this is the first time ANN-SNN conversion can simultaneously achieve high accuracy and ultra-low-latency on the complex dataset. Code is available at https://github.com/hzc1208/ANN2SNN_SRP.}
}
@inproceedings{chen2023a,
	title        = {A Unified Framework for Soft Threshold Pruning},
	author       = {Yanqi Chen and Zhengyu Ma and Wei Fang and Xiawu Zheng and Zhaofei Yu and Yonghong Tian},
	year         = 2023,
	booktitle    = {International Conference on Learning Representations}
}
@inproceedings{hao2023bridging,
	title        = {Bridging the Gap between {ANN}s and {SNN}s by Calibrating Offset Spikes},
	author       = {Zecheng Hao and Jianhao Ding and Tong Bu and Tiejun Huang and Zhaofei Yu},
	year         = 2023,
	booktitle    = {International Conference on Learning Representations}
}
@article{chen2023training,
	title        = {Training Full Spike Neural Networks via Auxiliary Accumulation Pathway},
	author       = {Chen, Guangyao and Peng, Peixi and Li, Guoqi and Tian, Yonghong},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2301.11929}
}
@article{yao2023sparser,
  title={Sparser Spiking Activity Can Be Better: Feature Refine-and-Mask Spiking Neural Network for Event-Based Visual Recognition},
  author={Yao, Man and Zhang, Hengyu and Zhao, Guangshe and Zhang, Xiyu and Wang, Dingheng and Cao, Gang and Li, Guoqi},
  journal={Neural Networks},
  volume={166},
  pages={410--423},
  year={2023},
  publisher={Elsevier}
}
@inproceedings{
huang2022tada,
title={TAda! Temporally-Adaptive Convolutions for Video Understanding},
author={Ziyuan Huang and Shiwei Zhang and Liang Pan and Zhiwu Qing and Mingqian Tang and Ziwei Liu and Marcelo H Ang Jr},
booktitle={International Conference on Learning Representations},
year={2022}
}
@inproceedings{wang2018non,
  title={Non-local Neural Networks},
  author={Wang, Xiaolong and Girshick, Ross and Gupta, Abhinav and He, Kaiming},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={7794--7803},
  year={2018}
}

@inproceedings{
xu2023enhancing,
 author = {Xu, Qi and Gao, Yuyuan and Shen, Jiangrong and Li, Yaxin and Ran, Xuming and Tang, Huajin and Pan, Gang},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {58890--58901},
 publisher = {Curran Associates, Inc.},
 title = {Enhancing Adaptive History Reserving by Spiking Convolutional Block Attention Module in Recurrent Neural Networks},
 volume = {36},
 year = {2023}
}


@article{10032591,
	title        = {Attention Spiking Neural Networks},
	author       = {Yao, Man and Zhao, Guangshe and Zhang, Hengyu and Hu, Yifan and Deng, Lei and Tian, Yonghong and Xu, Bo and Li, Guoqi},
	year         = 2023,
	journal      = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume       = 45,
	number       = 8,
	pages        = {9393--9410},
	doi          = {10.1109/TPAMI.2023.3241201}
}
@article{froemke2006contribution,
	title        = {Contribution of Individual Spikes in Burst-Induced Long-Term Synaptic Modification},
	author       = {Froemke, Robert C and Tsay, Ishan A and Raad, Mohamad and Long, John D and Dan, Yang},
	year         = 2006,
	journal      = {Journal of Neurophysiology},
	volume       = 95,
	number       = 3,
	pages        = {1620--1629}
}
@inproceedings{duan2022temporal,
	title        = {Temporal Effective Batch Normalization in Spiking Neural Networks},
	author       = {Chaoteng Duan and Jianhao Ding and Shiyan Chen and Zhaofei Yu and Tiejun Huang},
	year         = 2022,
	booktitle    = {Advances in Neural Information Processing Systems}
}
@inproceedings{zhang2022spiking,
  title={Spiking Transformers for Event-Based Single Object Tracking},
  author={Zhang, Jiqing and Dong, Bo and Zhang, Haiwei and Ding, Jianchuan and Heide, Felix and Yin, Baocai and Yang, Xin},
  booktitle={Proceedings of the IEEE/CVF conference on Computer Vision and Pattern Recognition},
  pages={8801--8810},
  year={2022}
}
@inproceedings{zhang2022spike,
  title={Spike Transformer: Monocular Depth Estimation for Spiking Camera},
  author={Zhang, Jiyuan and Tang, Lulu and Yu, Zhaofei and Lu, Jiwen and Huang, Tiejun},
  booktitle={European Conference on Computer Vision},
  pages={34--52},
  year={2022},
  organization={Springer}
}
@article{han2023complex,
  title={Complex Dynamic Neurons Improved Spiking Transformer Network for Efficient Automatic Speech Recognition},
  author={Han, Minglun and Wang, Qingyu and Zhang, Tielin and Wang, Yi and Zhang, Duzhen and Xu, Bo},
  journal={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2023}
}
@inproceedings{yao2022glif,
	title        = {{GLIF}: a Unified Gated Leaky Integrate-and-Fire Neuron for Spiking Neural Networks},
	author       = {Xingting Yao and Fanrong Li and Zitao Mo and Jian Cheng},
	year         = 2022,
	booktitle    = {Advances in Neural Information Processing Systems}
}
@article{ba2016layer,
	title        = {Layer Normalization},
	author       = {Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
	year         = 2016,
	journal      = {arXiv preprint arXiv:1607.06450}
}
@inproceedings{yang2022training,
	title        = {Training Spiking Neural Networks with Local Tandem Learning},
	author       = {Qu Yang and Jibin Wu and Malu Zhang and Yansong Chua and Xinchao Wang and Haizhou Li},
	year         = 2022,
	booktitle    = {Advances in Neural Information Processing Systems}
}
@inproceedings{xiao2022online,
	title        = {Online Training Through Time for Spiking Neural Networks},
	author       = {Mingqing Xiao and Qingyan Meng and Zongpeng Zhang and Di He and Zhouchen Lin},
	year         = 2022,
	booktitle    = {Advances in Neural Information Processing Systems}
}
@article{yu2022stsc,
	title        = {STSC-SNN: Spatio-Temporal Synaptic Connection with Temporal Convolution and Attention for Spiking Neural Networks},
	author       = {Yu, Chengting  and Gu, Zheming  and Li, Da  and Wang, Gaoang  and Wang, Aili  and Li, Erping},
	year         = 2022,
	journal      = {Frontiers in Neuroscience},
	volume       = 16,
	doi          = {10.3389/fnins.2022.1079357},
	issn         = {1662-453X}
}
@article{arxiv.2210.06836,
	title        = {SNN-SC: a Spiking Semantic Communication Framework for Classification},
	author       = {Wang, Mengyang and Li, Jiahui and Ma, Mengyao and Fan, Xiaopeng},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2210.06836}
}
@inproceedings{zhou2023spikformer,
	title        = {Spikformer: When Spiking Neural Network Meets Transformer},
	author       = {Zhaokun Zhou and Yuesheng Zhu and Chao He and Yaowei Wang and Shuicheng YAN and Yonghong Tian and Li Yuan},
	year         = 2023,
	booktitle    = {International Conference on Learning Representations}
}
@article{xiang2022spiking,
	title        = {Spiking SiamFC++: Deep Spiking Neural Network for Object Tracking},
	author       = {Xiang, Shuiying and Zhang, Tao and Jiang, Shuqing and Han, Yanan and Zhang, Yahui and Guo, Xingxing and Yu, Licun and Shi, Yuechun and Hao, Yue},
	year         = 2024,
	day          = {01},
	journal      = {Nonlinear Dynamics},
	volume       = 112,
	number       = 10,
	pages        = {8417--8429},
	doi          = {10.1007/s11071-024-09525-8},
	issn         = {1573-269X},
	abstract     = {Spiking neural network (SNN) is a biologically-plausible model and exhibits advantages of high computational capability and low power consumption. While the training of deep SNN is still an open problem, which limits the real-world applications of deep SNN. Here we propose a deep SNN architecture named Spiking SiamFC++ for object tracking with end-to-end direct training. Specifically, the AlexNet network is extended in the time domain to extract the feature, and the surrogate gradient function is adopted to realize direct supervised training of the deep SNN. To examine the performance of the Spiking SiamFC++, several tracking benchmarks including OTB2013, OTB2015, VOT2015, VOT2016, and UAV123 are considered. It is found that, the precision loss is small compared with the original SiamFC++. Compared with the existing SNN-based target tracker, e.g., the SiamSNN, the precision (success) of the proposed Spiking SiamFC++ reaches 0.861 (0.644), which is much higher than that of 0.528 (0.443) achieved by the SiamSNN. To our best knowledge, the performance of the Spiking SiamFC++ outperforms the existing state-of-the-art approaches in SNN-based object tracking, which provides a novel path for SNN application in the field of target tracking. This work may further promote the development of SNN algorithms and neuromorphic chips.}
}
@article{zheng2022label,
	title        = {Label Distribution Learning via Implicit Distribution Representation},
	author       = {Zheng, Zhuoran and Jia, Xiuyi},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2209.13824}
}
@article{10.7554/eLife.65459,
	title        = {Spike Frequency Adaptation Supports Network Computations on Temporally Dispersed Information},
	author       = {Salaj, Darjan and Subramoney, Anand and Kraisnikovic, Ceca and Bellec, Guillaume and Legenstein, Robert and Maass, Wolfgang},
	year         = 2021,
	journal      = {eLife},
	volume       = 10,
	pages        = {e65459},
	doi          = {10.7554/eLife.65459},
	issn         = {2050-084X},
	article_type = {journal},
	pub_date     = {2021-07-26},
	citation     = {eLife 2021;10:e65459},
	abstract     = {For solving tasks such as recognizing a song, answering a question, or inverting a sequence of symbols, cortical microcircuits need to integrate and manipulate information that was dispersed over time during the preceding seconds. Creating biologically realistic models for the underlying computations, especially with spiking neurons and for behaviorally relevant integration time spans, is notoriously difficult. We examine the role of spike frequency adaptation in such computations and find that it has a surprisingly large impact. The inclusion of this well-known property of a substantial fraction of neurons in the neocortex - especially in higher areas of the human neocortex - moves the performance of spiking neural network models for computations on network inputs that are temporally dispersed from a fairly low level up to the performance level of the human brain.},
	keywords     = {computational neuroscience, simulation, working memory, spiking neurons, spike-frequency adaptation}
}
@article{stockl2021optimized,
	title        = {Optimized Spiking Neurons Can Classify Images with High Accuracy through Temporal Coding with Two Spikes},
	author       = {St{\"o}ckl, Christoph and Maass, Wolfgang},
	year         = 2021,
	journal      = {Nature Machine Intelligence},
	volume       = 3,
	number       = 3,
	pages        = {230--238}
}
@inproceedings{lew2022time,
	title        = {A Time-to-First-Spike Coding and Conversion Aware Training for Energy-Efficient Deep Spiking Neural Network Processor Design},
	author       = {Lew, Dongwoo and Lee, Kyungchul and Park, Jongsun},
	year         = 2022,
	booktitle    = {Proceedings of the 59th ACM/IEEE Design Automation Conference},
	pages        = {265--270}
}
@inproceedings{10.5555/3437539.3437564,
	title        = {T2FSNN: Deep Spiking Neural Networks with Time-to-First-Spike Coding},
	author       = {Park, Seongsik and Kim, Seijoon and Na, Byunggook and Yoon, Sungroh},
	year         = 2020,
	booktitle    = {Proceedings of the 57th ACM/EDAC/IEEE Design Automation Conference},
	series       = {DAC '20},
	isbn         = 9781450367257,
	articleno    = 25,
	numpages     = 6,
	keywords     = {neuromorphics, supervised learning, biological neural networks, image classification}
}
@article{zheng2024temporal,
	title        = {Temporal Dendritic Heterogeneity Incorporated with Spiking Neural Networks for Learning Multi-Timescale Dynamics},
	author       = {Zheng, Hanle and Zheng, Zhong and Hu, Rui and Xiao, Bo and Wu, Yujie and Yu, Fangwen and Liu, Xue and Li, Guoqi and Deng, Lei},
	year         = 2024,
	journal      = {Nature Communications},
	volume       = 15,
	number       = 1,
	pages        = 277
}
@inproceedings{zhu2022training,
	title        = {Training Spiking Neural Networks with Event-driven Backpropagation},
	author       = {Yaoyu Zhu and Zhaofei Yu and Wei Fang and Xiaodong Xie and Tiejun Huang and Timoth{\'e}e Masquelier},
	year         = 2022,
	booktitle    = {Advances in Neural Information Processing Systems}
}
@inproceedings{kim2023c,
	title        = {C-DNN: a 24.5-85.8 TOPS/W Complementary-Deep-Neural-Network Processor with Heterogeneous CNN/SNN Core Architecture and Forward-Gradient-Based Sparsity Generation},
	author       = {Kim, Sangyeob and Kim, Soyeon and Hong, Seongyon and Kim, Sangjin and Han, Donghyeon and Yoo, Hoi-Jun},
	year         = 2023,
	booktitle    = {IEEE International Solid-State Circuits Conference},
	pages        = {334--336},
	organization = {IEEE}
}
@inproceedings{chang202373,
	title        = {A Heterogeneous RRAM In-Memory and SRAM Near-Memory SoC for Fused Frame and Event-Based Target Identification and Tracking},
	author       = {Chang, Muya and Lele, Ashwin Sanjay and Spetalnick, Samuel D. and Crafton, Brian and Konno, Shota and Wan, Zishen and Bhat, Ashwin and Khwa, Win-San and Chih, Yu-Der and Chang, Meng-Fan and Raychowdhury, Arijit},
	year         = 2023,
	booktitle    = {IEEE International Solid-State Circuits Conference},
	pages        = {426--428},
	organization = {IEEE}
}
@article{rao2022long,
	title        = {A Long Short-Term Memory for AI Applications in Spike-based Neuromorphic Hardware},
	author       = {Rao, Arjun and Plank, Philipp and Wild, Andreas and Maass, Wolfgang},
	year         = 2022,
	journal      = {Nature Machine Intelligence},
	volume       = 4,
	number       = 5,
	pages        = {467--479}
}
@article{yin2021accurate,
	title        = {Accurate and Efficient Time-domain Classification with Adaptive Spiking Recurrent Neural Networks},
	author       = {Yin, Bojian and Corradi, Federico and Boht{\'e}, Sander M},
	year         = 2021,
	journal      = {Nature Machine Intelligence},
	volume       = 3,
	number       = 10,
	pages        = {905--913}
}
@inproceedings{choy20194d,
	title        = {4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks},
	author       = {Choy, Christopher and Gwak, JunYoung and Savarese, Silvio},
	year         = 2019,
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {3075--3084}
}
@inproceedings{bellec2018long,
	title        = {Long Short-Term Memory and Learning-To-Learn in Networks of Spiking Neurons},
	author       = {Bellec, Guillaume and Salaj, Darjan and Subramoney, Anand and Legenstein, Robert and Maass, Wolfgang},
	year         = 2018,
	booktitle    = {Advances in Neural Information Processing Systems},
	volume       = 31
}
@inproceedings{zhang2022multi,
	title        = {Multi-Sacle Dynamic Coding Improved Spiking Actor Network for Reinforcement Learning},
	author       = {Zhang, Duzhen and Zhang, Tielin and Jia, Shuncheng and Xu, Bo},
	year         = 2022,
	booktitle    = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume       = 36,
	number       = 1,
	pages        = {59--67}
}
@inproceedings{ponghiran2022spiking,
	title        = {Spiking Neural Networks with Improved Inherent Recurrence Dynamics for Sequential Learning},
	author       = {Ponghiran, Wachirawit and Roy, Kaushik},
	year         = 2022,
	booktitle    = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume       = 36,
	number       = 7,
	pages        = {8001--8008}
}
@article{bengio2013estimating,
	title        = {Estimating or Propagating Gradients through Stochastic Neurons for Conditional Computation},
	author       = {Bengio, Yoshua and L{\'e}onard, Nicholas and Courville, Aaron},
	year         = 2013,
	journal      = {arXiv preprint arXiv:1308.3432}
}
@inproceedings{loshchilov2016sgdr,
	title        = {{SGDR}: Stochastic Gradient Descent with Warm Restarts},
	author       = {Ilya Loshchilov and Frank Hutter},
	year         = 2017,
	booktitle    = {International Conference on Learning Representations}
}
@inproceedings{shymyrbay2023low,
	title        = {Low Precision Quantization-aware Training in Spiking Neural Networks with Differentiable Quantization Function},
	author       = {Shymyrbay, Ayan and Fouda, Mohammed E. and Eltawil, Ahmed},
	year         = 2023,
	booktitle    = {International Joint Conference on Neural Networks},
	volume       = {},
	number       = {},
	pages        = {1--8},
	doi          = {10.1109/IJCNN54540.2023.10191387},
	keywords     = {Training;Quantization (signal);Costs;Memory management;Focusing;Artificial neural networks;Machine learning;spiking neural networks;memory compression;quantization;binarization;edge computing}
}
@inproceedings{tang2021deep,
	title        = {Deep Reinforcement Learning with Population-Coded Spiking Neural Network for Continuous Control},
	author       = {Tang, Guangzhi and Kumar, Neelesh and Yoo, Raymond and Michmizos, Konstantinos},
	year         = 2021,
	booktitle    = {Conference on Robot Learning},
	pages        = {2016--2029},
	organization = {PMLR}
}
@inproceedings{fujimoto2018addressing,
	title        = {Addressing Function Approximation Error in Actor-Critic Methods},
	author       = {Fujimoto, Scott and Hoof, Herke and Meger, David},
	year         = 2018,
	booktitle    = {International Conference on Machine Learning},
	pages        = {1587--1596},
	organization = {PMLR}
}
@inproceedings{wang2020shenjing,
	title        = {Shenjing: a Low Power Reconfigurable Neuromorphic Accelerator with Partial-Sum and Spike Networks-On-Chip},
	author       = {Wang, Bo and Zhou, Jun and Wong, Weng-Fai and Peh, Li-Shiuan},
	year         = 2020,
	booktitle    = {Design, Automation \& Test in Europe Conference \& Exhibition},
	pages        = {240--245},
	organization = {IEEE}
}
@inproceedings{6757323,
	title        = {1.1 Computing's Energy Problem (And What We Can Do about It)},
	author       = {Horowitz, Mark},
	year         = 2014,
	booktitle    = {IEEE International Solid-State Circuits Conference Digest of Technical Papers},
	volume       = {},
	number       = {},
	pages        = {10--14},
	doi          = {10.1109/ISSCC.2014.6757323},
	keywords     = {CMOS integrated circuits;Hardware;Transistors;Voltage control;CMOS technology;Energy efficiency;Logic gates}
}
@article{hu2020spiking,
	title        = {Spiking Deep Residual Networks},
	author       = {Hu, Yangfan and Tang, Huajin and Pan, Gang},
	year         = 2023,
	journal      = {IEEE Transactions on Neural Networks and Learning Systems},
	volume       = 34,
	number       = 8,
	pages        = {5200--5205},
	doi          = {10.1109/TNNLS.2021.3119238},
	keywords     = {Neurons;Convolutional neural networks;Task analysis;Biological neural networks;Residual neural networks;Membrane potentials;Low latency communication;Deep neural network;deep residual network (ResNet);neuromorphic computing;spiking neural networks (SNNs)}
}
@article{pan2023full,
	title        = {A Full-Stack Platform for Spiking Deep Learning},
	author       = {Pan, Jie},
	year         = 2023,
	journal      = {Nature Computational Science},
	volume       = 3,
	number       = 11,
	pages        = {913--913}
}
@inproceedings{fang2023parallel,
	title        = {Parallel Spiking Neurons with High Efficiency and Ability to Learn Long-term Dependencies},
	author       = {Wei Fang and Zhaofei Yu and Zhaokun Zhou and Ding Chen and Yanqi Chen and Zhengyu Ma and Timoth{\'e}e Masquelier and Yonghong Tian},
	year         = 2023,
	booktitle    = {Advances in Neural Information Processing Systems}
}
@article{harris2007parallel,
	title        = {Parallel Prefix Sum (Scan) with CUDA},
	author       = {Harris, Mark and Sengupta, Shubhabrata and Owens, John D},
	year         = 2007,
	journal      = {GPU Gems},
	volume       = 3,
	number       = 39,
	pages        = {851--876}
}
@article{bonilla2022analyzing,
	title        = {Analyzing Time-to-First-Spike Coding Schemes},
	author       = {Bonilla, Lina and Gautrais, Jacques and Thorpe, Simon and Masquelier, Timoth{\'e}e},
	year         = 2022,
	journal      = {Frontiers in Neuroscience},
	volume       = 16
}
@article{kheradpisheh2022bs4nn,
	title        = {BS4NN: Binarized Spiking Neural Networks with Temporal Coding and Learning},
	author       = {Kheradpisheh, Saeed Reza and Mirsadeghi, Maryam and Masquelier, Timoth{\'e}e},
	year         = 2022,
	journal      = {Neural Processing Letters},
	volume       = 54,
	number       = 2,
	pages        = {1255--1273}
}
@article{jiang2023klif,
	title        = {KLIF: an Optimized Spiking Neuron Unit for Tuning Surrogate Gradient Slope and Membrane Potential},
	author       = {Jiang, Chunming and Zhang, Yilei},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2302.09238}
}
@article{perez2021neural,
	title        = {Neural Heterogeneity Promotes Robust Learning},
	author       = {Perez-Nieves, Nicolas and Leung, Vincent CH and Dragotti, Pier Luigi and Goodman, Dan FM},
	year         = 2021,
	journal      = {Nature Communications},
	volume       = 12,
	number       = 1,
	pages        = 5791
}
@inproceedings{ijcai2022p343,
	title        = {Multi-Level Firing with Spiking DS-ResNet: Enabling Better and Deeper Directly-Trained Spiking Neural Networks},
	author       = {Feng, Lang and Liu, Qianhui and Tang, Huajin and Ma, De and Pan, Gang},
	year         = 2022,
	booktitle    = {International Joint Conference on Artificial Intelligence},
	pages        = {2471--2477},
	doi          = {10.24963/ijcai.2022/343}
}
@inproceedings{ioffe2015batch,
	title        = {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
	author       = {Ioffe, Sergey and Szegedy, Christian},
	year         = 2015,
	booktitle    = {International Conference on Machine Learning},
	pages        = {448--456},
	organization = {PMLR}
}
@article{10.3389/fnins.2021.773954,
	title        = {Revisiting Batch Normalization for Training Low-Latency Deep Spiking Neural Networks From Scratch},
	author       = {Kim, Youngeun and Panda, Priyadarshini},
	year         = 2021,
	journal      = {Frontiers in Neuroscience},
	volume       = 15,
	doi          = {10.3389/fnins.2021.773954},
	issn         = {1662-453X},
	abstract     = {Spiking Neural Networks (SNNs) have recently emerged as an alternative to deep learning owing to sparse, asynchronous and binary event (or spike) driven processing, that can yield huge energy efficiency benefits on neuromorphic hardware. However, SNNs convey temporally-varying spike activation through time that is likely to induce a large variation of forward activation and backward gradients, resulting in unstable training. To address this training issue in SNNs, we revisit Batch Normalization (BN) and propose a temporal Batch Normalization Through Time (BNTT) technique. Different from previous BN techniques with SNNs, we find that varying the BN parameters at every time-step allows the model to learn the time-varying input distribution better. Specifically, our proposed BNTT decouples the parameters in a BNTT layer along the time axis to capture the temporal dynamics of spikes. We demonstrate BNTT on CIFAR-10, CIFAR-100, Tiny-ImageNet, event-driven DVS-CIFAR10 datasets, and Sequential MNIST and show near state-of-the-art performance. We conduct comprehensive analysis on the temporal characteristic of BNTT and showcase interesting benefits toward robustness against random and adversarial noise. Further, by monitoring the learnt parameters of BNTT, we find that we can do temporal early exit. That is, we can reduce the inference latency by ~5 - 20 time-steps from the original training latency. The code has been released at <ext-link ext-link-type="uri" xlink:href="https://github.com/Intelligent-Computing-Lab-Yale/BNTT-Batch-Normalization-Through-Time" xmlns:xlink="http://www.w3.org/1999/xlink">https://github.com/Intelligent-Computing-Lab-Yale/BNTT-Batch-Normalization-Through-Time</ext-link>.}
}
@inproceedings{perez-nieves2021sparse,
	title        = {Sparse Spiking Gradient Descent},
	author       = {Nicolas Perez-Nieves and Dan F. M. Goodman},
	year         = 2021,
	booktitle    = {Advances in Neural Information Processing Systems}
}
@inproceedings{li2021differentiable,
	title        = {Differentiable Spike: Rethinking Gradient-Descent for Training Spiking Neural Networks},
	author       = {Yuhang Li and Yufei Guo and Shanghang Zhang and Shikuang Deng and Yongqing Hai and Shi Gu},
	year         = 2021,
	booktitle    = {Advances in Neural Information Processing Systems}
}
@inproceedings{deng2022temporal,
	title        = {Temporal Efficient Training of Spiking Neural Network via Gradient Re-weighting},
	author       = {Shikuang Deng and Yuhang Li and Shanghang Zhang and Shi Gu},
	year         = 2022,
	booktitle    = {International Conference on Learning Representations}
}
@article{rathi2021diet,
	title        = {DIET-SNN: a Low-Latency Spiking Neural Network with Direct Input Encoding and Leakage and Threshold Optimization},
	author       = {Rathi, Nitin and Roy, Kaushik},
	year         = 2021,
	journal      = {IEEE Transactions on Neural Networks and Learning Systems}
}
@article{kalchbrenner2016neural,
	title        = {Neural Machine Translation in Linear Time},
	author       = {Kalchbrenner, Nal and Espeholt, Lasse and Simonyan, Karen and Oord, Aaron van den and Graves, Alex and Kavukcuoglu, Koray},
	year         = 2016,
	journal      = {arXiv preprint arXiv:1610.10099}
}
@inproceedings{gehring2017convolutional,
	title        = {Convolutional Sequence to Sequence Learning},
	author       = {Gehring, Jonas and Auli, Michael and Grangier, David and Yarats, Denis and Dauphin, Yann N},
	year         = 2017,
	booktitle    = {International Conference on Machine Learning},
	pages        = {1243--1252},
	organization = {PMLR}
}
@inproceedings{martin2018parallelizing,
	title        = {Parallelizing Linear Recurrent Neural Nets Over Sequence Length},
	author       = {Eric Martin and Chris Cundy},
	year         = 2018,
	booktitle    = {International Conference on Learning Representations}
}
@inproceedings{muller2021trivialaugment,
	title        = {Trivialaugment: Tuning-Free yet State-of-the-Art Data Augmentation},
	author       = {M{\"u}ller, Samuel G and Hutter, Frank},
	year         = 2021,
	booktitle    = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages        = {774--782}
}
@inproceedings{yun2019cutmix,
	title        = {CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features},
	author       = {Yun, Sangdoo and Han, Dongyoon and Oh, Seong Joon and Chun, Sanghyuk and Choe, Junsuk and Yoo, Youngjoon},
	year         = 2019,
	booktitle    = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages        = {6023--6032}
}
@inproceedings{zhang2017mixup,
	title        = {Mixup: Beyond Empirical Risk Minimization},
	author       = {Hongyi Zhang and Moustapha Cisse and Yann N. Dauphin and David Lopez-Paz},
	year         = 2018,
	booktitle    = {International Conference on Learning Representations}
}
@inproceedings{zhong2020random,
	title        = {Random Erasing Data Augmentation},
	author       = {Zhong, Zhun and Zheng, Liang and Kang, Guoliang and Li, Shaozi and Yang, Yi},
	year         = 2020,
	booktitle    = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume       = 34,
	number       = {07},
	pages        = {13001--13008}
}
@inproceedings{szegedy2016rethinking,
	title        = {Rethinking the Inception Architecture for Computer Vision},
	author       = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
	year         = 2016,
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {2818--2826}
}
@inproceedings{10.1007/978-3-030-36718-3_15,
	title        = {Homeostasis-Based CNN-To-SNN Conversion of Inception and Residual Architectures},
	author       = {Xing, Fu and Yuan, Ye and Huo, Hong and Fang, Tao},
	year         = 2019,
	booktitle    = {International Conference on Neural Information Processing},
	pages        = {173--184},
	organization = {Springer}
}
@article{10.3389/fnins.2021.629000,
	title        = {Low-Latency Spiking Neural Networks Using Pre-Charged Membrane Potential and Delayed Evaluation},
	author       = {Hwang, Sungmin and Chang, Jeesoo and Oh, Min-Hye and Min, Kyung Kyu and Jang, Taejin and Park, Kyungchul and Yu, Junsu and Lee, Jong-Ho and Park, Byung-Gook},
	year         = 2021,
	journal      = {Frontiers in Neuroscience},
	volume       = 15,
	pages        = 135
}
@inproceedings{amir2017low,
	title        = {A Low Power, Fully Event-Based Gesture Recognition System},
	author       = {Amir, Arnon and Taba, Brian and Berg, David and Melano, Timothy and McKinstry, Jeffrey and Di Nolfo, Carmelo and Nayak, Tapan and Andreopoulos, Alexander and Garreau, Guillaume and Mendoza, Marcela and Kusnitz, Jeff and Debole, Michael and Esser, Steve and Delbruck, Tobi and Flickner, Myron and Modha, Dharmendra},
	year         = 2017,
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {7243--7252}
}
@article{bengio2007scaling,
	title        = {Scaling Learning Algorithms Towards AI},
	author       = {Bengio, Yoshua and LeCun, Yann and others},
	year         = 2007,
	journal      = {Large-scale Kernel Machines},
	volume       = 34,
	number       = 5,
	pages        = {1--41}
}
@inproceedings{comsa2020temporal,
	title        = {Temporal Coding in Spiking Neural Networks with Alpha Synaptic Function},
	author       = {Comsa, Iulia M and Potempa, Krzysztof and Versari, Luca and Fischbacher, Thomas and Gesmundo, Andrea and Alakuijala, Jyrki},
	year         = 2020,
	booktitle    = {International Conference on Acoustics, Speech and Signal Processing},
	pages        = {8529--8533},
	organization = {IEEE}
}
@article{goyal2018accurate,
	title        = {Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour},
	author       = {Goyal, Priya and Doll{\'a}r, Piotr and Girshick, Ross and Noordhuis, Pieter and Wesolowski, Lukasz and Kyrola, Aapo and Tulloch, Andrew and Jia, Yangqing and He, Kaiming},
	year         = 2017,
	journal      = {arXiv preprint arXiv:1706.02677}
}
@inproceedings{he2015convolutional,
	title        = {Convolutional Neural Networks at Constrained Time Cost},
	author       = {He, Kaiming and Sun, Jian},
	year         = 2015,
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {5353--5360}
}
@inproceedings{he2016identity,
	title        = {Identity Mappings in Deep Residual Networks},
	author       = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	year         = 2016,
	booktitle    = {European Conference on Computer Vision},
	pages        = {630--645},
	organization = {Springer}
}
@article{HE2020108,
	title        = {Comparing SNNs and RNNs on Neuromorphic Vision Datasets: Similarities and Differences},
	author       = {He, Weihua and Wu, YuJie and Deng, Lei and Li, Guoqi and Wang, Haoyu and Tian, Yang and Ding, Wei and Wang, Wenhui and Xie, Yuan},
	year         = 2020,
	journal      = {Neural Networks},
	volume       = 132,
	pages        = {108--120}
}
@article{hinton2012deep,
	title        = {Deep Neural Networks for Acoustic Modeling in Speech Recognition: the Shared Views of Four Research Groups},
	author       = {Hinton, Geoffrey and Deng, Li and Yu, Dong and Dahl, George E and Mohamed, Abdel-rahman and Jaitly, Navdeep and Senior, Andrew and Vanhoucke, Vincent and Nguyen, Patrick and Sainath, Tara N and others},
	year         = 2012,
	journal      = {IEEE Signal Processing Magazine},
	volume       = 29,
	number       = 6,
	pages        = {82--97}
}
@inproceedings{huang2017densely,
	title        = {Densely Connected Convolutional Networks},
	author       = {Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
	year         = 2017,
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {4700--4708}
}
@inproceedings{huh2017gradient,
	title        = {Gradient Descent for Spiking Neural Networks},
	author       = {Huh, Dongsung and Sejnowski, Terrence J},
	year         = 2018,
	booktitle    = {Advances in Neural Information Processing Systems},
	pages        = {1440--1450}
}
@article{i2016squeezenet,
	title        = {SqueezeNet: AlexNet-level Accuracy with 50x Fewer Parameters and< 0.5 Mb Model Size},
	author       = {Iandola, Forrest N and Han, Song and Moskewicz, Matthew W and Ashraf, Khalid and Dally, William J and Keutzer, Kurt},
	year         = 2016,
	journal      = {arXiv preprint arXiv:1602.07360}
}
@article{kheradpisheh2020temporal,
	title        = {Temporal Backpropagation for Spiking Neural Networks with One Spike per Neuron},
	author       = {Kheradpisheh, Saeed Reza and Masquelier, Timoth{\'e}e},
	year         = 2020,
	journal      = {International Journal of Neural Systems},
	volume       = 30,
	number       = {06},
	pages        = 2050027
}
@article{mostafa2017supervised,
	title        = {Supervised Learning Based on Temporal Coding in Spiking Neural Networks},
	author       = {Mostafa, Hesham},
	year         = 2017,
	journal      = {IEEE Transactions on Neural Networks and Learning Systems},
	volume       = 29,
	number       = 7,
	pages        = {3227--3235}
}
@inproceedings{NIPS2014_109d2dd3,
	title        = {On the Number of Linear Regions of Deep Neural Networks},
	author       = {Montufar, Guido F and Pascanu, Razvan and Cho, Kyunghyun and Bengio, Yoshua},
	year         = 2014,
	booktitle    = {Advances in Neural Information Processing Systems},
	pages        = {2924--2932}
}
@inproceedings{PYTORCH,
	title        = {PyTorch: an Imperative Style, High-Performance Deep Learning Library},
	author       = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
	year         = 2019,
	booktitle    = {Advances in Neural Information Processing Systems},
	pages        = {8026--8037}
}
@inproceedings{rathi2020enabling,
	title        = {Enabling Deep Spiking Neural Networks with Hybrid Conversion and Spike Timing Dependent Backpropagation},
	author       = {Nitin Rathi and Gopalakrishnan Srinivasan and Priyadarshini Panda and Kaushik Roy},
	year         = 2020,
	booktitle    = {International Conference on Learning Representations}
}
@inproceedings{s2018mobilenetv2,
	title        = {MobileNetV2: Inverted Residuals and Linear Bottlenecks},
	author       = {Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
	year         = 2018,
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {4510--4520},
	doi          = {10.1109/CVPR.2018.00474}
}
@article{s21093240,
	title        = {Exploring Optimized Spiking Neural Network Architectures for Classification Tasks on Embedded Platforms},
	author       = {Syed, Tehreem and Kakani, Vijay and Cui, Xuenan and Kim, Hakil},
	year         = 2021,
	journal      = {Sensors},
	volume       = 21,
	number       = 9,
	pages        = 3240
}
@article{samadzadeh2021convolutional,
	title        = {Convolutional Spiking Neural Networks for Spatio-Temporal Feature Extraction},
	author       = {Samadzadeh, Ali and Far, Fatemeh Sadat Tabatabaei and Javadi, Ali and Nickabadi, Ahmad and Chehreghani, Morteza Haghir},
	year         = 2023,
	day          = {01},
	journal      = {Neural Processing Letters},
	volume       = 55,
	number       = 6,
	pages        = {6979--6995},
	doi          = {10.1007/s11063-023-11247-8},
	issn         = {1573-773X}
}
@inproceedings{simonyan2015deep,
	title        = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
	author       = {Karen Simonyan and Andrew Zisserman},
	year         = 2015,
	booktitle    = {International Conference on Learning Representations},
	timestamp    = {Wed, 17 Jul 2019 10:40:54 +0200},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{srivastava2015highway,
	title        = {Highway Networks},
	author       = {Srivastava, Rupesh Kumar and Greff, Klaus and Schmidhuber, J{\"u}rgen},
	year         = 2015,
	journal      = {arXiv preprint arXiv:1505.00387}
}
@inproceedings{tan2018mnasnet,
	title        = {MnasNet: Platform-Aware Neural Architecture Search for Mobile},
	author       = {Tan, Mingxing and Chen, Bo and Pang, Ruoming and Vasudevan, Vijay and Sandler, Mark and Howard, Andrew and Le, Quoc V.},
	year         = 2019,
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {2815--2823},
	doi          = {10.1109/CVPR.2019.00293}
}
@article{TAVANAEI201947,
	title        = {Deep Learning in Spiking Neural Networks},
	author       = {Tavanaei, Amirhossein and Ghodrati, Masoud and Kheradpisheh, Saeed Reza and Masquelier, Timoth{\'e}e and Maida, Anthony},
	year         = 2019,
	journal      = {Neural Networks},
	volume       = 111,
	pages        = {47--63}
}
@article{wu2018STBP,
	title        = {Spatio-Temporal Backpropagation for Training High-Performance Spiking Neural Networks},
	author       = {Wu, Yujie and Deng, Lei and Li, Guoqi and Zhu, Jun and Shi, Luping},
	year         = 2018,
	journal      = {Frontiers in Neuroscience},
	volume       = 12,
	pages        = 331
}
@inproceedings{xie2016aggregated,
	title        = {Aggregated Residual Transformations for Deep Neural Networks},
	author       = {Xie, Saining and Girshick, Ross and Dollár, Piotr and Tu, Zhuowen and He, Kaiming},
	year         = 2017,
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {5987--5995},
	doi          = {10.1109/CVPR.2017.634}
}
@inproceedings{yin2020effective,
	title        = {Effective and Efficient Computation with Multiple-timescale Spiking Recurrent Neural Networks},
	author       = {Yin, Bojian and Corradi, Federico and Boht{\'e}, Sander M},
	year         = 2020,
	booktitle    = {International Conference on Neuromorphic Systems},
	pages        = {1--8}
}
@inproceedings{zhang2020temporal,
	title        = {Temporal Spike Sequence Learning via Backpropagation for Deep Spiking Neural Networks},
	author       = {Zhang, Wenrui and Li, Peng},
	year         = 2020,
	booktitle    = {Advances in Neural Information Processing Systems},
	pages        = {12022--12033}
}
@inproceedings{zhou2019temporal,
	title        = {Temporal-Coded Deep Spiking Neural Network with Easy Training and Robust Performance},
	author       = {Zhou, Shibo and Li, Xiaohua and Chen, Ying and Chandrasekaran, Sanjeev T. and Sanyal, Arindam},
	year         = 2021,
	booktitle    = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume       = 35,
	number       = 12,
	pages        = {11143--11151},
	abstractnote = {Spiking neural network (SNN) is promising but the development has fallen far behind conventional deep neural networks (DNNs) because of difficult training. To resolve the training problem, we analyze the closed-form input-output response of spiking neurons and use the response expression to build abstract SNN models for training. This avoids calculating membrane potential during training and makes the direct training of SNN as efficient as DNN. We show that the nonleaky integrate-and-fire neuron with single-spike temporal-coding is the best choice for direct-train deep SNNs. We develop an energy-efficient phase-domain signal processing circuit for the neuron and propose a direct-train deep SNN framework. Thanks to easy training, we train deep SNNs under weight quantizations to study their robustness over low-cost neuromorphic hardware. Experiments show that our direct-train deep SNNs have the highest CIFAR-10 classification accuracy among SNNs, achieve ImageNet classification accuracy within 1% of the DNN of equivalent architecture, and are robust to weight quantization and noise perturbation.}
}
@article{zimmer2019technical,
	title        = {Technical Report: Supervised Training of Convolutional Spiking Neural Networks with Pytorch},
	author       = {Zimmer, Romain and Pellegrini, Thomas and Singh, Srisht Fateh and Masquelier, Timoth{\'e}e},
	year         = 2019,
	journal      = {arXiv preprint arXiv:1911.10124}
}
@inproceedings{micikevicius2018mixed,
	title        = {Mixed Precision Training},
	author       = {Micikevicius, Paulius and Narang, Sharan and Alben, Jonah and Diamos, Gregory and Elsen, Erich and Garcia, David and Ginsburg, Boris and Houston, Michael and Kuchaiev, Oleksii and Venkatesh, Ganesh and others},
	year         = 2018,
	booktitle    = {International Conference on Learning Representations}
}
@article{mattia2002population,
	title        = {Population Dynamics of Interacting Spiking Neurons},
	author       = {Mattia, Maurizio and Del Giudice, Paolo},
	year         = 2002,
	journal      = {Physical Review E},
	volume       = 66,
	number       = 5,
	pages        = {051917}
}
@article{2019Brain,
	title        = {Brain Songs Framework Used for Discovering the Relevant Timescale of the Human Brain},
	author       = {Deco, Gustavo and Cruzat, Josephine and Kringelbach, Morten L},
	year         = 2019,
	journal      = {Nature Communications},
	volume       = 10,
	number       = 1,
	pages        = {1--13}
}
@article{2006Mechanisms,
	title        = {Mechanisms Underlying Working Memory for Novel Information},
	author       = {Hasselmo, Michael E and Stern, Chantal E},
	year         = 2006,
	journal      = {Trends in Cognitive Sciences},
	volume       = 10,
	number       = 11,
	pages        = {487--493}
}
@article{Shankar2012A,
	title        = {A Scale-Invariant Internal Representation of Time},
	author       = {Shankar, Karthik H and Howard, Marc W},
	year         = 2012,
	journal      = {Neural Computation},
	volume       = 24,
	number       = 1,
	pages        = {134--193}
}
@article{koch1996a,
	title        = {A Brief History of Time (Constants)},
	author       = {Koch, Christof and  Rapp, Moshe and Segev, Idan},
	year         = 1996,
	journal      = {Cerebral Cortex},
	volume       = 6,
	number       = 2,
	pages        = {93--101}
}
@inproceedings{yu2015multi,
	title        = {Multi-Scale Context Aggregation by Dilated Convolutions},
	author       = {Fisher Yu and Vladlen Koltun},
	year         = 2016,
	booktitle    = {International Conference on Learning Representations},
	timestamp    = {Tue, 19 Sep 2023 07:33:34 +0200},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{pmlr-v15-glorot11a,
	title        = {Deep Sparse Rectifier Neural Networks},
	author       = {Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
	year         = 2011,
	booktitle    = {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
	address      = {Fort Lauderdale, FL, USA},
	series       = {Proceedings of Machine Learning Research},
	volume       = 15,
	pages        = {315--323},
	pdf          = {http://proceedings.mlr.press/v15/glorot11a/glorot11a.pdf},
	abstract     = {While logistic sigmoid neurons are more biologically plausible than hyperbolic tangent neurons, the latter work better for training multi-layer neural networks. This paper shows that rectifying neurons are an even better model of biological neurons and yield equal or better performance than hyperbolic tangent networks in spite of the hard non-linearity and non-differentiability at zero, creating sparse representations with true zeros which seem remarkably suitable for naturally sparse data. Even though they can take advantage of semi-supervised setups with extra-unlabeled data, deep rectifier networks can reach their best performance without requiring any unsupervised pre-training on purely supervised tasks with large labeled datasets. Hence, these results can be seen as a new milestone in the attempts at understanding the difficulty in training deep but purely supervised neural networks, and closing the performance gap between neural networks learnt with and without unsupervised pre-training.}
}
@article{benjamin2014neurogrid,
	title        = {Neurogrid: a Mixed-Analog-Digital Multichip System for Large-scale Neural Simulations},
	author       = {Benjamin, Ben Varkey and Gao, Peiran and McQuinn, Emmett and Choudhary, Swadesh and Chandrasekaran, Anand R and Bussat, Jean-Marie and Alvarez-Icaza, Rodrigo and Arthur, John V and Merolla, Paul A and Boahen, Kwabena},
	year         = 2014,
	journal      = {Proceedings of the IEEE},
	volume       = 102,
	number       = 5,
	pages        = {699--716}
}
@article{moradi2017scalable,
	title        = {A Scalable Multicore Architecture with Heterogeneous Memory Structures for Dynamic Neuromorphic Asynchronous Processors (DYNAPs)},
	author       = {Moradi, Saber and Qiao, Ning and Stefanini, Fabio and Indiveri, Giacomo},
	year         = 2017,
	journal      = {IEEE Transactions on Biomedical Circuits and Systems},
	volume       = 12,
	number       = 1,
	pages        = {106--122}
}
@article{qiao2015reconfigurable,
	title        = {A Reconfigurable On-Line Learning Spiking Neuromorphic Processor Comprising 256 Neurons and 128k Synapses},
	author       = {Qiao, Ning and Mostafa, Hesham and Corradi, Federico and Osswald, Marc and Stefanini, Fabio and Sumislawska, Dora and Indiveri, Giacomo},
	year         = 2015,
	journal      = {Frontiers in Neuroscience},
	volume       = 9,
	pages        = 141
}
@article{ma2017darwin,
	title        = {Darwin: a Neuromorphic Hardware Co-processor Based on Spiking Neural Networks},
	author       = {Ma, De and Shen, Juncheng and Gu, Zonghua and Zhang, Ming and Zhu, Xiaolei and Xu, Xiaoqiang and Xu, Qi and Shen, Yangjing and Pan, Gang},
	year         = 2017,
	journal      = {Journal of Systems Architecture},
	volume       = 77,
	pages        = {43--51}
}
@article{1175509,
	title        = {A Biomorphic Digital Image Sensor},
	author       = {Culurciello, E. and Etienne-Cummings, R. and Boahen, K.A.},
	year         = 2003,
	journal      = {IEEE Journal of Solid-State Circuits},
	volume       = 38,
	number       = 2,
	pages        = {281--294},
	doi          = {10.1109/JSSC.2002.807412},
	keywords     = {Digital images;Image sensors;Biosensors;Pixel;Dynamic range;Lighting;Energy consumption;CMOS process;Bandwidth;Encoding}
}
@article{jianingli2021,
	title        = {神经形态视觉传感器的研究进展及应用综述},
	author       = {李家宁 and 田永鸿},
	year         = 2021,
	journal      = {计算机学报},
	volume       = 44,
	number       = 6,
	pages        = {1258--1286},
	language     = {chinese}
}
@article{maro2020event,
	title        = {Event-Based Gesture Recognition with Dynamic Background Suppression Using Smartphone Computational Capabilities},
	author       = {Maro, Jean-Matthieu and Ieng, Sio-Hoi and Benosman, Ryad},
	year         = 2020,
	journal      = {Frontiers in Neuroscience},
	volume       = 14,
	pages        = 275
}
@article{mead1990neuromorphic,
	title        = {Neuromorphic Electronic Systems},
	author       = {Mead, Carver},
	year         = 1990,
	journal      = {Proceedings of the IEEE},
	volume       = 78,
	number       = 10,
	pages        = {1629--1636}
}
@article{7f54e8f1-602c-3d67-8301-2981f48e0297,
	title        = {The Silicon Retina},
	author       = {Misha A. Mahowald and Carver Mead},
	year         = 1991,
	journal      = {Scientific American},
	volume       = 264,
	number       = 5,
	pages        = {76--83},
	issn         = {00368733, 19467087}
}
@inproceedings{4541871,
	title        = {An Asynchronous Time-based Image Sensor},
	author       = {Posch, Christoph and Matolin, Daniel and Wohlgenannt, Rainer},
	year         = 2008,
	booktitle    = {IEEE International Symposium on Circuits and Systems},
	pages        = {2130--2133},
	doi          = {10.1109/ISCAS.2008.4541871},
	keywords     = {Image sensors;Image resolution;Dynamic range;Energy consumption;Photoconductivity;Encoding;Lighting;Measurement standards;CMOS process;Semiconductor device measurement}
}
@inproceedings{NEURIPS2022_b5fd95d6,
	title        = {LTMD: Learning Improvement of Spiking Neural Networks with Learnable Thresholding Neurons and Moderate Dropout},
	author       = {Wang, Siqi and Cheng, Tee Hiang and Lim, Meng-Hiot},
	year         = 2022,
	booktitle    = {Advances in Neural Information Processing Systems},
	volume       = 35,
	pages        = {28350--28362}
}
@article{10423179,
	title        = {Fully Spiking Actor Network With Intralayer Connections for Reinforcement Learning},
	author       = {Chen, Ding and Peng, Peixi and Huang, Tiejun and Tian, Yonghong},
	year         = 2024,
	journal      = {IEEE Transactions on Neural Networks and Learning Systems},
	volume       = {},
	number       = {},
	pages        = {1--13},
	doi          = {10.1109/TNNLS.2024.3352653},
	keywords     = {Neurons;Task analysis;Statistics;Sociology;Hardware;Firing;Membrane potentials;Brain-inspired intelligence;intralayer connections;neuromorphic engineering;nonspiking neurons;reinforcement learning (RL);spiking neural networks (SNNs)}
}



@ARTICLE{10428029,
  author={Hu, Yifan and Deng, Lei and Wu, Yujie and Yao, Man and Li, Guoqi},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Advancing Spiking Neural Networks Toward Deep Residual Learning}, 
  year={2024},
  pages={1-15},
  keywords={Degradation;Training;Task analysis;Neurons;Neuromorphics;Computer architecture;Computational modeling;Degradation problem;neuromorphic computing;residual neural network;spiking neural network (SNN)},
  doi={10.1109/TNNLS.2024.3355393}}









@article{doi:10.1126/sciadv.adi1480,
author = {Wei Fang  and Yanqi Chen  and Jianhao Ding  and Zhaofei Yu  and Timothée Masquelier  and Ding Chen  and Liwei Huang  and Huihui Zhou  and Guoqi Li  and Yonghong Tian },
title = {SpikingJelly: An open-source machine learning infrastructure platform for spike-based intelligence},
journal = {Science Advances},
volume = {9},
number = {40},
pages = {eadi1480},
year = {2023},
doi = {10.1126/sciadv.adi1480},
abstract = {Spiking neural networks (SNNs) aim to realize brain-inspired intelligence on neuromorphic chips with high energy efficiency by introducing neural dynamics and spike properties. As the emerging spiking deep learning paradigm attracts increasing interest, traditional programming frameworks cannot meet the demands of the automatic differentiation, parallel computation acceleration, and high integration of processing neuromorphic datasets and deployment. In this work, we present the SpikingJelly framework to address the aforementioned dilemma. We contribute a full-stack toolkit for preprocessing neuromorphic datasets, building deep SNNs, optimizing their parameters, and deploying SNNs on neuromorphic chips. Compared to existing methods, the training of deep SNNs can be accelerated 11×, and the superior extensibility and flexibility of SpikingJelly enable users to accelerate custom models at low costs through multilevel inheritance and semiautomatic code generation. SpikingJelly paves the way for synthesizing truly energy-efficient SNN-based machine intelligence systems, which will enrich the ecology of neuromorphic computing. Motivation and introduction of the software framework SpikingJelly for spiking deep learning.}}


@inproceedings{NEURIPS2023_b9f253c2,
 author = {Taylor, Luke and King, Andrew and Harper, Nicol S},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {59360--59374},
 publisher = {Curran Associates, Inc.},
 title = {Addressing the Speed-Accuracy Simulation Trade-off for Adaptive Spiking Neurons},
 volume = {36},
 year = {2023}
}


@InProceedings{Guo_2023_ICCV_rmp,
    author    = {Guo, Yufei and Liu, Xiaode and Chen, Yuanpei and Zhang, Liwen and Peng, Weihang and Zhang, Yuhan and Huang, Xuhui and Ma, Zhe},
    title     = {RMP-Loss: Regularizing Membrane Potential Distribution for Spiking Neural Networks},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
    month     = {October},
    year      = {2023},
    pages     = {17391-17401}
}

@InProceedings{Guo_2023_ICCV_mpbn,
    author    = {Guo, Yufei and Zhang, Yuhan and Chen, Yuanpei and Peng, Weihang and Liu, Xiaode and Zhang, Liwen and Huang, Xuhui and Ma, Zhe},
    title     = {Membrane Potential Batch Normalization for Spiking Neural Networks},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
    month     = {October},
    year      = {2023},
    pages     = {19420-19430}
}

@inproceedings{NEURIPS2020_1457c0d6,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {1877--1901},
 publisher = {Curran Associates, Inc.},
 title = {Language Models are Few-Shot Learners},
 volume = {33},
 year = {2020}
}
@misc{openai2024gpt4technicalreport,
      title={GPT-4 Technical Report}, 
      author={OpenAI and Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haiming Bao and Mohammad Bavarian and Jeff Belgum and Irwan Bello and Jake Berdine and Gabriel Bernadett-Shapiro and Christopher Berner and Lenny Bogdonoff and Oleg Boiko and Madelaine Boyd and Anna-Luisa Brakman and Greg Brockman and Tim Brooks and Miles Brundage and Kevin Button and Trevor Cai and Rosie Campbell and Andrew Cann and Brittany Carey and Chelsea Carlson and Rory Carmichael and Brooke Chan and Che Chang and Fotis Chantzis and Derek Chen and Sully Chen and Ruby Chen and Jason Chen and Mark Chen and Ben Chess and Chester Cho and Casey Chu and Hyung Won Chung and Dave Cummings and Jeremiah Currier and Yunxing Dai and Cory Decareaux and Thomas Degry and Noah Deutsch and Damien Deville and Arka Dhar and David Dohan and Steve Dowling and Sheila Dunning and Adrien Ecoffet and Atty Eleti and Tyna Eloundou and David Farhi and Liam Fedus and Niko Felix and Simón Posada Fishman and Juston Forte and Isabella Fulford and Leo Gao and Elie Georges and Christian Gibson and Vik Goel and Tarun Gogineni and Gabriel Goh and Rapha Gontijo-Lopes and Jonathan Gordon and Morgan Grafstein and Scott Gray and Ryan Greene and Joshua Gross and Shixiang Shane Gu and Yufei Guo and Chris Hallacy and Jesse Han and Jeff Harris and Yuchen He and Mike Heaton and Johannes Heidecke and Chris Hesse and Alan Hickey and Wade Hickey and Peter Hoeschele and Brandon Houghton and Kenny Hsu and Shengli Hu and Xin Hu and Joost Huizinga and Shantanu Jain and Shawn Jain and Joanne Jang and Angela Jiang and Roger Jiang and Haozhun Jin and Denny Jin and Shino Jomoto and Billie Jonn and Heewoo Jun and Tomer Kaftan and Łukasz Kaiser and Ali Kamali and Ingmar Kanitscheider and Nitish Shirish Keskar and Tabarak Khan and Logan Kilpatrick and Jong Wook Kim and Christina Kim and Yongjik Kim and Jan Hendrik Kirchner and Jamie Kiros and Matt Knight and Daniel Kokotajlo and Łukasz Kondraciuk and Andrew Kondrich and Aris Konstantinidis and Kyle Kosic and Gretchen Krueger and Vishal Kuo and Michael Lampe and Ikai Lan and Teddy Lee and Jan Leike and Jade Leung and Daniel Levy and Chak Ming Li and Rachel Lim and Molly Lin and Stephanie Lin and Mateusz Litwin and Theresa Lopez and Ryan Lowe and Patricia Lue and Anna Makanju and Kim Malfacini and Sam Manning and Todor Markov and Yaniv Markovski and Bianca Martin and Katie Mayer and Andrew Mayne and Bob McGrew and Scott Mayer McKinney and Christine McLeavey and Paul McMillan and Jake McNeil and David Medina and Aalok Mehta and Jacob Menick and Luke Metz and Andrey Mishchenko and Pamela Mishkin and Vinnie Monaco and Evan Morikawa and Daniel Mossing and Tong Mu and Mira Murati and Oleg Murk and David Mély and Ashvin Nair and Reiichiro Nakano and Rajeev Nayak and Arvind Neelakantan and Richard Ngo and Hyeonwoo Noh and Long Ouyang and Cullen O'Keefe and Jakub Pachocki and Alex Paino and Joe Palermo and Ashley Pantuliano and Giambattista Parascandolo and Joel Parish and Emy Parparita and Alex Passos and Mikhail Pavlov and Andrew Peng and Adam Perelman and Filipe de Avila Belbute Peres and Michael Petrov and Henrique Ponde de Oliveira Pinto and Michael and Pokorny and Michelle Pokrass and Vitchyr H. Pong and Tolly Powell and Alethea Power and Boris Power and Elizabeth Proehl and Raul Puri and Alec Radford and Jack Rae and Aditya Ramesh and Cameron Raymond and Francis Real and Kendra Rimbach and Carl Ross and Bob Rotsted and Henri Roussez and Nick Ryder and Mario Saltarelli and Ted Sanders and Shibani Santurkar and Girish Sastry and Heather Schmidt and David Schnurr and John Schulman and Daniel Selsam and Kyla Sheppard and Toki Sherbakov and Jessica Shieh and Sarah Shoker and Pranav Shyam and Szymon Sidor and Eric Sigler and Maddie Simens and Jordan Sitkin and Katarina Slama and Ian Sohl and Benjamin Sokolowsky and Yang Song and Natalie Staudacher and Felipe Petroski Such and Natalie Summers and Ilya Sutskever and Jie Tang and Nikolas Tezak and Madeleine B. Thompson and Phil Tillet and Amin Tootoonchian and Elizabeth Tseng and Preston Tuggle and Nick Turley and Jerry Tworek and Juan Felipe Cerón Uribe and Andrea Vallone and Arun Vijayvergiya and Chelsea Voss and Carroll Wainwright and Justin Jay Wang and Alvin Wang and Ben Wang and Jonathan Ward and Jason Wei and CJ Weinmann and Akila Welihinda and Peter Welinder and Jiayi Weng and Lilian Weng and Matt Wiethoff and Dave Willner and Clemens Winter and Samuel Wolrich and Hannah Wong and Lauren Workman and Sherwin Wu and Jeff Wu and Michael Wu and Kai Xiao and Tao Xu and Sarah Yoo and Kevin Yu and Qiming Yuan and Wojciech Zaremba and Rowan Zellers and Chong Zhang and Marvin Zhang and Shengjia Zhao and Tianhao Zheng and Juntang Zhuang and William Zhuk and Barret Zoph},
      year={2024},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}

@misc{zeng2021pangualphalargescaleautoregressivepretrained,
      title={PanGu-$\alpha$: Large-scale Autoregressive Pretrained Chinese Language Models with Auto-parallel Computation}, 
      author={Wei Zeng and Xiaozhe Ren and Teng Su and Hui Wang and Yi Liao and Zhiwei Wang and Xin Jiang and ZhenZhang Yang and Kaisheng Wang and Xiaoda Zhang and Chen Li and Ziyan Gong and Yifan Yao and Xinjing Huang and Jun Wang and Jianfeng Yu and Qi Guo and Yue Yu and Yan Zhang and Jin Wang and Hengtao Tao and Dasen Yan and Zexuan Yi and Fang Peng and Fangqing Jiang and Han Zhang and Lingfeng Deng and Yehong Zhang and Zhe Lin and Chao Zhang and Shaojie Zhang and Mingyue Guo and Shanzhi Gu and Gaojun Fan and Yaowei Wang and Xuefeng Jin and Qun Liu and Yonghong Tian},
      year={2021},
      eprint={2104.12369},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}

@Article{Bi2023,
author={Bi, Kaifeng
and Xie, Lingxi
and Zhang, Hengheng
and Chen, Xin
and Gu, Xiaotao
and Tian, Qi},
title={Accurate Medium-Range Global Weather Forecasting with 3D Neural Networks},
journal={Nature},
year={2023},
month={Jul},
day={01},
volume={619},
number={7970},
pages={533-538},
issn={1476-4687},
doi={10.1038/s41586-023-06185-3},
}



@Article{Jumper2021,
author={Jumper, John
and Evans, Richard
and Pritzel, Alexander
and Green, Tim
and Figurnov, Michael
and Ronneberger, Olaf
and Tunyasuvunakool, Kathryn
and Bates, Russ
and {\v{Z}}{\'i}dek, Augustin
and Potapenko, Anna
and Bridgland, Alex
and Meyer, Clemens
and Kohl, Simon A. A.
and Ballard, Andrew J.
and Cowie, Andrew
and Romera-Paredes, Bernardino
and Nikolov, Stanislav
and Jain, Rishub
and Adler, Jonas
and Back, Trevor
and Petersen, Stig
and Reiman, David
and Clancy, Ellen
and Zielinski, Michal
and Steinegger, Martin
and Pacholska, Michalina
and Berghammer, Tamas
and Bodenstein, Sebastian
and Silver, David
and Vinyals, Oriol
and Senior, Andrew W.
and Kavukcuoglu, Koray
and Kohli, Pushmeet
and Hassabis, Demis},
title={Highly Accurate Protein Structure Prediction with Alphafold},
journal={Nature},
year={2021},
month={Aug},
day={01},
volume={596},
number={7873},
pages={583-589},
issn={1476-4687},
doi={10.1038/s41586-021-03819-2},
}










@article{doi:10.1126/science.adg7492,
author = {Jun Cheng  and Guido Novati  and Joshua Pan  and Clare Bycroft  and Akvilė Žemgulytė  and Taylor Applebaum  and Alexander Pritzel  and Lai Hong Wong  and Michal Zielinski  and Tobias Sargeant  and Rosalia G. Schneider  and Andrew W. Senior  and John Jumper  and Demis Hassabis  and Pushmeet Kohli  and Žiga Avsec },
title = {Accurate Proteome-wide Missense Variant Effect Prediction with Alphamissense},
journal = {Science},
volume = {381},
number = {6664},
pages = {eadg7492},
year = {2023},
doi = {10.1126/science.adg7492},

@InProceedings{Rombach_2022_CVPR,
    author    = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj\"orn},
    title     = {High-Resolution Image Synthesis With Latent Diffusion Models},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {10684-10695}
}

@inproceedings{NIPS2014_5ca3e9b1,
 author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence and K.Q. Weinberger},
 publisher = {Curran Associates, Inc.},
 title = {Generative Adversarial Nets},
 volume = {27},
 year = {2014}
}
@inproceedings{DBLP:journals/corr/RadfordMC15,
  author       = {Alec Radford and
                  Luke Metz and
                  Soumith Chintala},
  editor       = {Yoshua Bengio and
                  Yann LeCun},
  title        = {Unsupervised Representation Learning with Deep Convolutional Generative
                  Adversarial Networks},
  booktitle    = {International Conference on Learning Representations},
  year         = {2016},
  timestamp    = {Thu, 25 Jul 2019 14:25:38 +0200},
}

@Article{Zador2023,
author={Zador, Anthony
and Escola, Sean
and Richards, Blake
and {\"O}lveczky, Bence
and Bengio, Yoshua
and Boahen, Kwabena
and Botvinick, Matthew
and Chklovskii, Dmitri
and Churchland, Anne
and Clopath, Claudia
and DiCarlo, James
and Ganguli, Surya
and Hawkins, Jeff
and K{\"o}rding, Konrad
and Koulakov, Alexei
and LeCun, Yann
and Lillicrap, Timothy
and Marblestone, Adam
and Olshausen, Bruno
and Pouget, Alexandre
and Savin, Cristina
and Sejnowski, Terrence
and Simoncelli, Eero
and Solla, Sara
and Sussillo, David
and Tolias, Andreas S.
and Tsao, Doris},
title={Catalyzing next-generation Artificial Intelligence through NeuroAI},
journal={Nature Communications},
year={2023},
month={Mar},
day={22},
volume={14},
number={1},
pages={1597},
abstract={Neuroscience has long been an essential driver of progress in artificial intelligence (AI). We propose that to accelerate progress in AI, we must invest in fundamental research in NeuroAI. A core component of this is the embodied Turing test, which challenges AI animal models to interact with the sensorimotor world at skill levels akin to their living counterparts. The embodied Turing test shifts the focus from those capabilities like game playing and language that are especially well-developed or uniquely human to those capabilities -- inherited from over 500 million years of evolution -- that are shared with all animals. Building models that can pass the embodied Turing test will provide a roadmap for the next generation of AI.},
issn={2041-1723},
doi={10.1038/s41467-023-37180-x},
}


@article{10.1162/neco.2006.18.7.1527,
    author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee-Whye},
    title = {A Fast Learning Algorithm for Deep Belief Nets},
    journal = {Neural Computation},
    volume = {18},
    number = {7},
    pages = {1527-1554},
    year = {2006},
    month = {07},
    issn = {0899-7667},
    doi = {10.1162/neco.2006.18.7.1527},

}


@Article{Wang2023,
author={Wang, Hanchen
and Fu, Tianfan
and Du, Yuanqi
and Gao, Wenhao
and Huang, Kexin
and Liu, Ziming
and Chandak, Payal
and Liu, Shengchao
and Van Katwyk, Peter
and Deac, Andreea
and Anandkumar, Anima
and Bergen, Karianne
and Gomes, Carla P.
and Ho, Shirley
and Kohli, Pushmeet
and Lasenby, Joan
and Leskovec, Jure
and Liu, Tie-Yan
and Manrai, Arjun
and Marks, Debora
and Ramsundar, Bharath
and Song, Le
and Sun, Jimeng
and Tang, Jian
and Veli{\v{c}}kovi{\'{c}}, Petar
and Welling, Max
and Zhang, Linfeng
and Coley, Connor W.
and Bengio, Yoshua
and Zitnik, Marinka},
title={Scientific Discovery in the Age of Artificial Intelligence},
journal={Nature},
year={2023},
month={Aug},
day={01},
volume={620},
number={7972},
pages={47-60},
abstract={Artificial intelligence (AI) is being increasingly integrated into scientific discovery to augment and accelerate research, helping scientists to generate hypotheses, design experiments, collect and interpret large datasets, and gain insights that might not have been possible using traditional scientific methods alone. Here we examine breakthroughs over the past decade that include self-supervised learning, which allows models to be trained on vast amounts of unlabelled data, and geometric deep learning, which leverages knowledge about the structure of scientific data to enhance model accuracy and efficiency. Generative AI methods can create designs, such as small-molecule drugs and proteins, by analysing diverse data modalities, including images and sequences. We discuss how these methods can help scientists throughout the scientific process and the central issues that remain despite such advances. Both developers and users of AI tools need a better understanding of when such approaches need improvement, and challenges posed by poor data quality and stewardship remain. These issues cut across scientific disciplines and require developing foundational algorithmic approaches that can contribute to scientific understanding or acquire it autonomously, making them critical areas of focus for AI innovation.},
issn={1476-4687},
doi={10.1038/s41586-023-06221-2},
}


@Article{Yao2024,
author={Yao, Man
and Richter, Ole
and Zhao, Guangshe
and Qiao, Ning
and Xing, Yannan
and Wang, Dingheng
and Hu, Tianxiang
and Fang, Wei
and Demirci, Tugba
and De Marchi, Michele
and Deng, Lei
and Yan, Tianyi
and Nielsen, Carsten
and Sheik, Sadique
and Wu, Chenxi
and Tian, Yonghong
and Xu, Bo
and Li, Guoqi},
title={Spike-based Dynamic Computing with Asynchronous Sensing-Computing Neuromorphic Chip},
journal={Nature Communications},
year={2024},
month={May},
day={25},
volume={15},
number={1},
pages={4464},
abstract={By mimicking the neurons and synapses of the human brain and employing spiking neural networks on neuromorphic chips, neuromorphic computing offers a promising energy-efficient machine intelligence. How to borrow high-level brain dynamic mechanisms to help neuromorphic computing achieve energy advantages is a fundamental issue. This work presents an application-oriented algorithm-software-hardware co-designed neuromorphic system for this issue. First, we design and fabricate an asynchronous chip called ``Speck'', a sensing-computing neuromorphic system on chip. With the low processor resting power of 0.42mW, Speck can satisfy the hardware requirements of dynamic computing: no-input consumes no energy. Second, we uncover the ``dynamic imbalance'' in spiking neural networks and develop an attention-based framework for achieving the algorithmic requirements of dynamic computing: varied inputs consume energy with large variance. Together, we demonstrate a neuromorphic system with real-time power as low as 0.70mW. This work exhibits the promising potentials of neuromorphic computing with its asynchronous event-driven, sparse, and dynamic nature.},
issn={2041-1723},
doi={10.1038/s41467-024-47811-6},
}

@Article{Yang2024,
author={Yang, Zheyu
and Wang, Taoyi
and Lin, Yihan
and Chen, Yuguo
and Zeng, Hui
and Pei, Jing
and Wang, Jiazheng
and Liu, Xue
and Zhou, Yichun
and Zhang, Jianqiang
and Wang, Xin
and Lv, Xinhao
and Zhao, Rong
and Shi, Luping},
title={A Vision Chip with Complementary Pathways for Open-World Sensing},
journal={Nature},
year={2024},
month={May},
day={01},
volume={629},
number={8014},
pages={1027-1033},
abstract={Image sensors face substantial challenges when dealing with dynamic, diverse and unpredictable scenes in open-world applications. However, the development of image sensors towards high speed, high resolution, large dynamic range and high precision is limited by power and bandwidth. Here we present a complementary sensing paradigm inspired by the human visual system that involves parsing visual information into primitive-based representations and assembling these primitives to form two complementary vision pathways: a cognition-oriented pathway for accurate cognition and an action-oriented pathway for rapid response. To realize this paradigm, a vision chip called Tianmouc is developed, incorporating a hybrid pixel array and a parallel-and-heterogeneous readout architecture. Leveraging the characteristics of the complementary vision pathway, Tianmouc achieves high-speed sensing of up to 10,000{\thinspace}fps, a dynamic range of 130{\thinspace}dB and an advanced figure of merit in terms of spatial resolution, speed and dynamic range. Furthermore, it adaptively reduces bandwidth by 90{\%}. We demonstrate the integration of a Tianmouc chip into an autonomous driving system, showcasing its abilities to enable accurate, fast and robust perception, even in challenging corner cases on open roads. The primitive-based complementary sensing paradigm helps in overcoming fundamental limitations in developing vision systems for diverse open-world applications.},
issn={1476-4687},
doi={10.1038/s41586-024-07358-4},
}


@article{10.1162/neco_a_01086,
    author = {Zenke, Friedemann and Ganguli, Surya},
    title = {SuperSpike: Supervised Learning in Multilayer Spiking Neural Networks},
    journal = {Neural Computation},
    volume = {30},
    number = {6},
    pages = {1514-1541},
    year = {2018},
    month = {06},
    abstract = "{A vast majority of computation in the brain is performed by spiking neural networks. Despite the ubiquity of such spiking, we currently lack an understanding of how biological spiking neural circuits learn and compute in vivo, as well as how we can instantiate such capabilities in artificial spiking circuits in silico. Here we revisit the problem of supervised learning in temporally coding multilayer spiking neural networks. First, by using a surrogate gradient approach, we derive SuperSpike, a nonlinear voltage-based three-factor learning rule capable of training multilayer networks of deterministic integrate-and-fire neurons to perform nonlinear computations on spatiotemporal spike patterns. Second, inspired by recent results on feedback alignment, we compare the performance of our learning rule under different credit assignment strategies for propagating output errors to hidden units. Specifically, we test uniform, symmetric, and random feedback, finding that simpler tasks can be solved with any type of feedback, while more complex tasks require symmetric feedback. In summary, our results open the door to obtaining a better scientific understanding of learning and computation in spiking neural networks by advancing our ability to train them to solve nonlinear problems involving transformations between different spatiotemporal spike time patterns.}",
    issn = {0899-7667},
    doi = {10.1162/neco_a_01086},
    eprint = {https://direct.mit.edu/neco/article-pdf/30/6/1514/1039264/neco\_a\_01086.pdf},
}


@inproceedings{
huang2024clif,
title={{CLIF}: Complementary Leaky Integrate-and-Fire Neuron for Spiking Neural Networks},
author={Yulong Huang and Xiaopeng LIN and Hongwei Ren and Haotian FU and Yue Zhou and Zunchang LIU and biao pan and Bojun Cheng},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
}

@INPROCEEDINGS{8351295,
  author={Rueckauer, Bodo and Liu, Shih-Chii},
  booktitle={IEEE International Symposium on Circuits and Systems}, 
  title={Conversion of analog to spiking neural networks using sparse temporal coding}, 
  year={2018},
  volume={},
  number={},
  pages={1-5},
  keywords={Encoding;Mathematical model;Biological neural networks;Hardware;Computational modeling},
  doi={10.1109/ISCAS.2018.8351295}}



@inproceedings{hammouamri2024learning,
title={Learning Delays in Spiking Neural Networks using Dilated Convolutions with Learnable Spacings},
author={Ilyass Hammouamri and Ismail Khalfaoui-Hassani and Timoth{\'e}e Masquelier},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
}


@INPROCEEDINGS{8050527,
  author={Mostafa, Hesham and Pedroni, Bruno U. and Sheik, Sadique and Cauwenberghs, Gert},
  booktitle={IEEE International Symposium on Circuits and Systems}, 
  title={Fast Classification Using Sparsely Active Spiking Networks}, 
  year={2017},
  volume={},
  number={},
  pages={1-4},
  keywords={Neurons;Field programmable gate arrays;Hardware;Training;Biological neural networks;Encoding;Adaptation models},
  doi={10.1109/ISCAS.2017.8050527}}

@misc{zhou2024qkformerhierarchicalspikingtransformer,
      title={QKFormer: Hierarchical Spiking Transformer using Q-K Attention}, 
      author={Chenlin Zhou and Han Zhang and Zhaokun Zhou and Liutao Yu and Liwei Huang and Xiaopeng Fan and Li Yuan and Zhengyu Ma and Huihui Zhou and Yonghong Tian},
      year={2024},
      eprint={2403.16552},
      archivePrefix={arXiv},
      primaryClass={cs.NE},
}

@InProceedings{Shi_2024_CVPR,
    author    = {Shi, Xinyu and Hao, Zecheng and Yu, Zhaofei},
    title     = {SpikingResformer: Bridging ResNet and Vision Transformer in Spiking Neural Networks},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    month     = {June},
    year      = {2024},
    pages     = {5610-5619}
}

@inproceedings{yao2024spikedriven,
title={Spike-driven Transformer V2: Meta Spiking Neural Network Architecture Inspiring the Design of Next-generation Neuromorphic Chips},
author={Man Yao and JiaKui Hu and Tianxiang Hu and Yifan Xu and Zhaokun Zhou and Yonghong Tian and Bo XU and Guoqi Li},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
}

@misc{graves2014generatingsequencesrecurrentneural,
      title={Generating Sequences With Recurrent Neural Networks}, 
      author={Alex Graves},
      year={2014},
      eprint={1308.0850},
      archivePrefix={arXiv},
      primaryClass={cs.NE},
}

@InProceedings{Yao_2023_ICCV,
    author    = {Yao, Man and Hu, Jiakui and Zhao, Guangshe and Wang, Yaoyuan and Zhang, Ziyang and Xu, Bo and Li, Guoqi},
    title     = {Inherent Redundancy in Spiking Neural Networks},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
    month     = {October},
    year      = {2023},
    pages     = {16924-16934}
}


#辅助训练 start
@article{wu2021tandem,
	Title = {A Tandem Learning Rule for Effective Training and Rapid Inference of Deep Spiking Neural Networks},
	Author = {Wu, Jibin and Chua, Yansong and Zhang, Malu and Li, Guoqi and Li, Haizhou and Tan, Kay Chen},
	DOI = {10.1109/tnnls.2021.3095724},
	Number = {1},
	Volume = {34},
	Month = {January},
	Year = {2023},
	Journal = {IEEE transactions on neural networks and learning systems},
	ISSN = {2162-237X},
	Pages = {446—460},
	Abstract = {Spiking neural networks (SNNs) represent the most prominent biologically inspired computing model for neuromorphic computing (NC) architectures. However, due to the nondifferentiable nature of spiking neuronal functions, the standard error backpropagation algorithm is not directly applicable to SNNs. In this work, we propose a tandem learning framework that consists of an SNN and an artificial neural network (ANN) coupled through weight sharing. The ANN is an auxiliary structure that facilitates the error backpropagation for the training of the SNN at the spike-train level. To this end, we consider the spike count as the discrete neural representation in the SNN and design an ANN neuronal activation function that can effectively approximate the spike count of the coupled SNN. The proposed tandem learning rule demonstrates competitive pattern recognition and regression capabilities on both the conventional frame- and event-based vision datasets, with at least an order of magnitude reduced inference time and total synaptic operations over other state-of-the-art SNN implementations. Therefore, the proposed tandem learning rule offers a novel solution to training efficient, low latency, and high-accuracy deep SNNs with low computing resources.},
}
@INPROCEEDINGS{kushawaha2021distilling,
  author={Kushawaha, Ravi Kumar and Kumar, Saurabh and Banerjee, Biplab and Velmurugan, Rajbabu},
  booktitle={International Conference on Pattern Recognition}, 
  title={Distilling Spikes: Knowledge Distillation in Spiking Neural Networks}, 
  year={2021},
  volume={},
  number={},
  pages={4536-4543},
  keywords={Knowledge engineering;Training;Image coding;Computational modeling;Artificial neural networks;Linear programming;Hardware},
  doi={10.1109/ICPR48806.2021.9412147}
}
@InProceedings{xu2023constructing,
    author    = {Xu, Qi and Li, Yaxin and Shen, Jiangrong and Liu, Jian K. and Tang, Huajin and Pan, Gang},
    title     = {Constructing Deep Spiking Neural Networks From Artificial Neural Networks With Knowledge Distillation},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    month     = {June},
    year      = {2023},
    pages     = {7886-7895}
}
@article{qiu2024self,
title = {Self-Architectural Knowledge Distillation for Spiking Neural Networks},
journal = {Neural Networks},
author = {Haonan Qiu and Munan Ning and Zeyin Song and Wei Fang and Yanqi Chen and Tao Sun and Zhengyu Ma and Li Yuan and Yonghong Tian},
volume = {178},
pages = {106475},
year = {2024},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2024.106475},
}

@misc{hassani2022escapingbigdataparadigm,
      title={Escaping the Big Data Paradigm with Compact Transformers}, 
      author={Ali Hassani and Steven Walton and Nikhil Shah and Abulikemu Abuduweili and Jiachen Li and Humphrey Shi},
      year={2022},
      eprint={2104.05704},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
}

@inproceedings{jiang2024ndot,
  title={NDOT: Neuronal Dynamics-based Online Training for Spiking Neural Networks},
  author={Jiang, Haiyan and De Masi, Giulia and Xiong, Huan and Gu, Bin},
  booktitle={International Conference on Machine Learning},
  year={2024}
}

@InProceedings{meng2023towards,
    author    = {Meng, Qingyan and Xiao, Mingqing and Yan, Shen and Wang, Yisen and Lin, Zhouchen and Luo, Zhi-Quan},
    title     = {Towards Memory- and Time-Efficient Backpropagation for Training Spiking Neural Networks},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
    month     = {October},
    year      = {2023},
    pages     = {6166-6176}
}

@inproceedings{
zhu2024online,
title={Online Stabilization of Spiking Neural Networks},
author={Yaoyu Zhu and Jianhao Ding and Tiejun Huang and Xiaodong Xie and Zhaofei Yu},
booktitle={International Conference on Learning Representations},
year={2024},
}

@inproceedings{
hu2024highperformance,
title={High-Performance Temporal Reversible Spiking Neural Networks with \${\textbackslash}mathcal\{O\}(L)\$ Training Memory and \${\textbackslash}mathcal\{O\}(1)\$ Inference Cost},
author={JiaKui Hu and Man Yao and Xuerui Qiu and Yuhong Chou and Yuxuan Cai and Ning Qiao and Yonghong Tian and Bo XU and Guoqi Li},
booktitle={International Conference on Machine Learning},
year={2024},
}

@article{zhu2024exploring,
  title={Exploring loss functions for time-based training strategy in spiking neural networks},
  author={Zhu, Yaoyu and Fang, Wei and Xie, Xiaodong and Huang, Tiejun and Yu, Zhaofei},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}